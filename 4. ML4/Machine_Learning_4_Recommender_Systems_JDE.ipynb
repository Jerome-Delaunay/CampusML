{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './Models/'\n",
    "\n",
    "## Calling `save('my_model.keras')` creates a zip archive `my_model.keras`.\n",
    "# model.save(model_path + \"my_model.keras\")\n",
    "\n",
    "## It can be used to reconstruct the model identically.\n",
    "# reconstructed_model = keras.models.load_model(\"my_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- conda create --name ML4 python=3.12\n",
    "    - conda activate ML4\n",
    "    - conda deactivate\n",
    "    - conda install -n ML4 keras\n",
    "    - conda install -n ML4 tensorflow\n",
    "\n",
    "    - conda install -n ML4 pandas ipykernel matplotlib seaborn\n",
    "    - conda install --name ML4 pydot\n",
    "    - conda install --name ML4 plotly\n",
    "\n",
    "    - conda install anaconda::keras,\n",
    "    - conda install pandas ipykernel matplotlib seaborn tensorflow scikit-learn\n",
    "        - use python 3.12 for conpatibility\n",
    "\n",
    "\n",
    "-  conda create --name KerasTensorFlow --clone ML4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources** :\n",
    "\n",
    "*Matrix Factorization techniques for Recommender Systems*, Koren (2009)    \n",
    "https://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/Koren_Matrix_Factorization.pdf\n",
    "\n",
    "Hands on Machine Learning with scikit-learn and tensorflow:             \n",
    "https://drive.google.com/file/d/1t0rc3x5YQBgLXVLET6BzR4jn5vzMI_m0/view?usp=sharing\n",
    "\n",
    "The movieLens dataset:                                                \n",
    "https://grouplens.org/datasets/movielens/ \n",
    "\n",
    "Keras Functional API doc :                                            \n",
    "https://keras.io/guides/functional_api/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems : collaborative filtering via matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you wonder how Netflix is able to recommend you movies despite it doesn't know anything about you but the ratings you gave to the movies you watched ? This is what we are going to explore during this 3 days machine learning module.\n",
    "\n",
    "First off, let's learn about what are recommender system, collaborative filtering and matrix factorization techniques, which are all very well introduced in Koren's 2009 famous article : *Matrix Factorization techniques for Recommender Systems* : https://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/Koren_Matrix_Factorization.pdf . Read the 4 first pages (up to section *adding biases* included). \n",
    "\n",
    "Through this notebook we are going to re-implement the model described in the pages you read, and apply it to a classic movie ratings dataset coming from the website *movieLens*. To do so, we will use a powerful deep learning python library called *Keras*, that makes it easy to train complex models based on linear algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My resume of the *Matrix Factorization techniques for Recommender Systems* : https://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/Koren_Matrix_Factorization.pdf \n",
    "\n",
    "Recomendation strategie:\n",
    "- content filtering\n",
    "- collaborative filtering\n",
    "       - neighborhood methods <br> exemple user oriented neighborhood methods\n",
    "       - latent factor models\n",
    "           - based on matrix\n",
    "    \n",
    "Leearning algo\n",
    "    - Stochastic gradient descent \n",
    "    http://sifter.org/~simon/journal/20061211.html\n",
    "    - Alternating least squares (ALS)\n",
    "    \n",
    "ADDING BIASES\n",
    "    \n",
    "ADDITIONAL INPUT SOURCES\n",
    "    \n",
    "TEMPORAL DYNAMICS\n",
    "    \n",
    "INPUTS WITH VARYING CONFIDENCE LEVELS\n",
    "    \n",
    "NETFLIX PRIZE COMPETITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My notes:\n",
    "- https://grouplens.org/datasets/movielens/latest/\n",
    "- https://www.kaggle.com/datasets/grouplens/movielens-20m-dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this module, we are going to use the movieLens dataset, that contains data from the movie recommending website movielens. The data is a subset of ratings from 0 to 5 given by some users of the website to a subset of movies. You can read more about it here (we are using the latest small dataset) : https://grouplens.org/datasets/movielens/ , and in the *README* file that is in the *data/ml-latest-small/* folder.\n",
    "\n",
    "Load the ratings data from the `ratings.csv` file into a dataframe. The userId and movieId provided in the file don't start from 0, and are not contiguous (i.e. there are missing indexes).\n",
    "\n",
    "Re-index the user and movie ids to indexes going from 0 to `nb_users` and 0 to `nb_movies` respectively, by building two dictionnaries `user_ids_map` and `movie_ids_map` that maps the file ids to your new ids. \n",
    "And finally, split the rows of this dataframe in a random 90%/10% train/test sets.\n",
    "\n",
    "To do so, fill the `get_train_test_sets` function below, and respect the returned objects structures that are described in the docstring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>newUserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>609</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>609</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>609</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>609</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>609</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  newUserId  movieId  rating   timestamp\n",
       "0            1          0        1     4.0   964982703\n",
       "1            1          0        3     4.0   964981247\n",
       "2            1          0        6     4.0   964982224\n",
       "3            1          0       47     5.0   964983815\n",
       "4            1          0       50     5.0   964982931\n",
       "...        ...        ...      ...     ...         ...\n",
       "100831     610        609   166534     4.0  1493848402\n",
       "100832     610        609   168248     5.0  1493850091\n",
       "100833     610        609   168250     5.0  1494273047\n",
       "100834     610        609   168252     5.0  1493846352\n",
       "100835     610        609   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>newUserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25535</th>\n",
       "      <td>177</td>\n",
       "      <td>176</td>\n",
       "      <td>45447</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1435526171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78857</th>\n",
       "      <td>489</td>\n",
       "      <td>488</td>\n",
       "      <td>4235</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1332706148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83707</th>\n",
       "      <td>534</td>\n",
       "      <td>533</td>\n",
       "      <td>4011</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1459787998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36277</th>\n",
       "      <td>247</td>\n",
       "      <td>246</td>\n",
       "      <td>54286</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1467644268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9479</th>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "      <td>365</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1161566490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65327</th>\n",
       "      <td>419</td>\n",
       "      <td>418</td>\n",
       "      <td>1097</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1321659113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>290</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1234570350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>2028</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1362016835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49973</th>\n",
       "      <td>321</td>\n",
       "      <td>320</td>\n",
       "      <td>802</td>\n",
       "      <td>5.0</td>\n",
       "      <td>843212681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25226</th>\n",
       "      <td>177</td>\n",
       "      <td>176</td>\n",
       "      <td>3052</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1435534292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90752 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  newUserId  movieId  rating   timestamp\n",
       "25535     177        176    45447     3.5  1435526171\n",
       "78857     489        488     4235     4.0  1332706148\n",
       "83707     534        533     4011     4.0  1459787998\n",
       "36277     247        246    54286     3.5  1467644268\n",
       "9479       64         63      365     4.0  1161566490\n",
       "...       ...        ...      ...     ...         ...\n",
       "65327     419        418     1097     0.5  1321659113\n",
       "4213       28         27      290     3.0  1234570350\n",
       "4802       29         28     2028     5.0  1362016835\n",
       "49973     321        320      802     5.0   843212681\n",
       "25226     177        176     3052     4.0  1435534292\n",
       "\n",
       "[90752 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>newUserId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964981208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100767</th>\n",
       "      <td>610</td>\n",
       "      <td>609</td>\n",
       "      <td>135569</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1493846966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100799</th>\n",
       "      <td>610</td>\n",
       "      <td>609</td>\n",
       "      <td>147657</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1479544210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100800</th>\n",
       "      <td>610</td>\n",
       "      <td>609</td>\n",
       "      <td>147662</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1479544214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100817</th>\n",
       "      <td>610</td>\n",
       "      <td>609</td>\n",
       "      <td>158956</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493848947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100824</th>\n",
       "      <td>610</td>\n",
       "      <td>609</td>\n",
       "      <td>161582</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493847759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10084 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  newUserId  movieId  rating   timestamp\n",
       "4            1          0       50     5.0   964982931\n",
       "5            1          0       70     3.0   964982400\n",
       "6            1          0      101     5.0   964980868\n",
       "11           1          0      216     5.0   964981208\n",
       "17           1          0      316     3.0   964982310\n",
       "...        ...        ...      ...     ...         ...\n",
       "100767     610        609   135569     3.5  1493846966\n",
       "100799     610        609   147657     4.0  1479544210\n",
       "100800     610        609   147662     3.0  1479544214\n",
       "100817     610        609   158956     3.0  1493848947\n",
       "100824     610        609   161582     4.0  1493847759\n",
       "\n",
       "[10084 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ml_latest_small_path= 'data/ml-latest-small/'#'./data/ml-latest-small/'\n",
    "\n",
    "ratings_s_path =  ml_latest_small_path+'ratings.csv'\n",
    "data= pd.read_csv(ratings_s_path, delimiter=',') # userId,movieId,rating,timestamp\n",
    "# display (ratings.describe())\n",
    "# display (ratings.userId.unique().tolist())\n",
    "# users=ratings.userId.unique().tolist()#.reset_index()\n",
    "\n",
    "user_ids_map = {value : index  for index, value in enumerate(data.userId.unique().tolist())}\n",
    "movie_ids_map = {int(value) : index  for index, value in enumerate(data.movieId.unique())}\n",
    "display (len(user_ids_map), data.userId.nunique())\n",
    "display (len(movie_ids_map), data.movieId.nunique())\n",
    "\n",
    "# display(movie_ids_map)\n",
    "\n",
    "# display(user_ids_map)\n",
    "# ratings['newUserId']=\n",
    "# ratings.apply(lambda x : user_ids_map[x.loc['userId']])\n",
    "\n",
    "# avec apply\n",
    "#ratings[\"newUserId\"]=ratings.apply(lambda x : user_ids_map[x.userId], axis=1)\n",
    "\n",
    "# avec maper insert\n",
    "data.insert(1, \"newUserId\", data.apply(lambda x : user_ids_map[x.userId], axis=1))\n",
    "\n",
    "\n",
    "train= data.sample(frac=0.9, axis=0)\n",
    "test= data.drop(train.index)\n",
    "display (data)\n",
    "display(train)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_sets(data_path, train_prop = 0.9):\n",
    "    \"\"\"\n",
    "    Build train and test sets and reindex userIds and MovieIds from 0 with contiguous indexes.\n",
    "    \n",
    "    Input: \n",
    "        data_path : string : the path to the ratings file\n",
    "        train_prop : float : The proportion of the training set \n",
    "    \n",
    "    Output:\n",
    "        train : pandas.DataFrame : A dataframe with columns [userId, movieId, rating, timestamp], where\n",
    "            the userId and movieId value have been replaced with new ids starting at 0. \n",
    "            Contains `train_prop` random entries from the input file.\n",
    "        test : pandas.DataFrame : Same as `train`, contains the 1 - `train_prop` remaining entries.\n",
    "        nb_users : int : Number of unique user ids\n",
    "        nb_movies : int : Number of unique movie ids\n",
    "        user_ids_map : dict : A mapping of original file userId to a new index starting at 0.\n",
    "            Keys are int from the original userId column, values are int of the new indexation.\n",
    "        movie_ids_map : dict : Same as `user_ids_map` for the movieIds.\n",
    "    \"\"\"\n",
    "    \n",
    "    #TOFILL\n",
    "    ratings= pd.read_csv(data_path, delimiter=',') # userId,movieId,rating,timestamp\n",
    "    \n",
    "    # create dict\n",
    "    user_ids_map = {value : index  for index, value in enumerate(ratings.sort_values(by=['userId']).userId.unique().tolist())}\n",
    "    movie_ids_map = {int(value) : index  for index, value in enumerate(ratings.sort_values(by=['movieId']).movieId.unique())}\n",
    "    # user_ids_map = {value : index  for index, value in enumerate(ratings.userId.unique().tolist())}\n",
    "    # movie_ids_map = {int(value) : index  for index, value in enumerate(ratings.movieId.unique())}\n",
    "    # movieids=dict(zip (....))\n",
    "\n",
    "    # get nb users / movies\n",
    "    nb_users=  ratings.userId.nunique() # len(user_ids_map)\n",
    "    nb_movies= len(movie_ids_map)      # ratings.movieId.nunique()\n",
    "\n",
    "    # update index of users with new id\n",
    "    ratings['userId'] = ratings['userId'].map(user_ids_map)\n",
    "    \n",
    "    # update index of movies with new id\n",
    "    ratings.insert(1, \"newMovieId\", ratings.apply(lambda x : movie_ids_map[x.movieId], axis=1))\n",
    "    ratings.drop(columns='movieId', inplace=True)\n",
    "    ratings.rename(columns={'newMovieId':'movieId'}, inplace=True )\n",
    "\n",
    "    display (ratings.describe())\n",
    "\n",
    "    train= ratings.sample(frac=0.9, axis=0)\n",
    "    test=  ratings.drop(train.index)\n",
    "\n",
    "    return train, test, nb_users, nb_movies, user_ids_map, movie_ids_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>1.008360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>325.127564</td>\n",
       "      <td>3101.735561</td>\n",
       "      <td>3.501557</td>\n",
       "      <td>1.205946e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>182.618491</td>\n",
       "      <td>2627.050983</td>\n",
       "      <td>1.042529</td>\n",
       "      <td>2.162610e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.281246e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.019124e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>324.000000</td>\n",
       "      <td>2252.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.186087e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>5095.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.435994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>609.000000</td>\n",
       "      <td>9723.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
       "mean      325.127564    3101.735561       3.501557  1.205946e+09\n",
       "std       182.618491    2627.050983       1.042529  2.162610e+08\n",
       "min         0.000000       0.000000       0.500000  8.281246e+08\n",
       "25%       176.000000     900.000000       3.000000  1.019124e+09\n",
       "50%       324.000000    2252.000000       3.500000  1.186087e+09\n",
       "75%       476.000000    5095.250000       4.000000  1.435994e+09\n",
       "max       609.000000    9723.000000       5.000000  1.537799e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9724 movies, 610 users, and 100836 ratings\n"
     ]
    }
   ],
   "source": [
    "ratings_s_path =  ml_latest_small_path+'ratings.csv'\n",
    "train, test, nb_users, nb_movies, user_ids_map, movie_ids_map = get_train_test_sets(ratings_s_path)\n",
    "dataset = pd.concat((train,test), axis = 0)\n",
    "\n",
    "print(\"There are %i movies, %i users, and %i ratings\" % (nb_movies, nb_users, dataset.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [train[\"userId\"].to_numpy(), train[\"movieId\"].to_numpy()]\n",
    "y_train = train[\"rating\"].to_numpy()\n",
    "\n",
    "X_test = [test[\"userId\"].to_numpy(), test[\"movieId\"].to_numpy()]\n",
    "y_test = test[\"rating\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5707770"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"movieId\"].nunique()*train[\"userId\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId         610\n",
       "movieId       9357\n",
       "rating          10\n",
       "timestamp    77215\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[\"movieId\"].sort_values(ascending=True).to_numpy())\n",
    "train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at the ratings distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['rating'].hist(bins=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset there are a lot of missing values, because not all the user/movie pairs have an associated rating. Indeed, each user rates only a few movies ! The goal of this notebook is to predict (some of) the missing user/movie ratings.\n",
    "\n",
    "Print \n",
    "1. how many movies each of the 5 first users have rated, \n",
    "2. and print the percentage of available ratings in the whole dataset (i.e. the ratio between number of ratings and all the possible users/movies combinations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many movies each of the 5 first users have rated:\n",
      " userId\n",
      "175      36\n",
      "189      66\n",
      "379    1218\n",
      "483     275\n",
      "486      56\n",
      "Name: movieId, dtype: int64\n",
      "How many movies each of the 5 first users have rated:\n",
      " userId    1651\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#TOFILL\n",
    "first5users= dataset.userId.unique()[0:5]\n",
    "nbDistinctMovies= dataset.movieId.nunique()\n",
    "# display(first5users, nbDistinctMovies)\n",
    "# display(dataset[dataset.userId.isin(first5users)])\n",
    "\n",
    "# 1.1- nb ranking pour les 5 premier users\n",
    "ranking5=dataset[dataset.userId.isin(first5users)].groupby('userId').movieId.count()\n",
    "print(f\"How many movies each of the 5 first users have rated:\\n {ranking5}\")\n",
    "\n",
    "# 1.2- nb ranking pour les 5 premier users\n",
    "nb_ranking5=dataset[dataset.userId.isin(first5users)].loc[:,['userId', 'movieId']].count()\n",
    "nb_ranking5=dataset[dataset.userId.isin(first5users)].loc[:,['userId']].count()\n",
    "print(f\"How many movies each of the 5 first users have rated:\\n {nb_ranking5}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of available ratings in the whole dataset 1.69996831\n"
     ]
    }
   ],
   "source": [
    "# 2. The percentage of available ratings in the whole dataset \n",
    "# (i.e. the ratio between number of ratings and all the possible users/movies combinations)\n",
    "\n",
    "pct= dataset.shape[0]/(nb_movies*nb_users)\n",
    "print(f\"Percentage of available ratings in the whole dataset {pct*100 :.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulls</th>\n",
       "      <th>non_nulls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nulls  non_nulls\n",
       "userId                  \n",
       "175        36         36\n",
       "189        66         66\n",
       "379      1218       1218\n",
       "483       275        275\n",
       "486        56         56"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset[dataset.userId.isin(first5users)].groupby('userId').count()\n",
    "# dataset[dataset.userId.isin(first5users)].rating.notna\n",
    "\n",
    "dataset[dataset.userId.isin(first5users)].groupby('userId').agg(nulls=('rating', lambda x: x.isna().count()), non_nulls=('rating', lambda x: x.notna().count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display userId / movieId rating pivot matrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only 1.7% of ratings that are available, which is normal as each hasn't rated all the movies. To see the dataset in a matrix form with all the missing ratings, use the `Dataframe.pivot()` function, with the `userId` as index, the `movieId` as columns, and the ratings for the `values` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9714</th>\n",
       "      <th>9715</th>\n",
       "      <th>9716</th>\n",
       "      <th>9717</th>\n",
       "      <th>9718</th>\n",
       "      <th>9719</th>\n",
       "      <th>9720</th>\n",
       "      <th>9721</th>\n",
       "      <th>9722</th>\n",
       "      <th>9723</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 9724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "userId                                                               ...   \n",
       "0         4.0   NaN   4.0   NaN   NaN   4.0   NaN   NaN   NaN   NaN  ...   \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "605       2.5   NaN   NaN   NaN   NaN   NaN   2.5   NaN   NaN   NaN  ...   \n",
       "606       4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "607       2.5   2.0   2.0   NaN   NaN   NaN   NaN   NaN   NaN   4.0  ...   \n",
       "608       3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   4.0  ...   \n",
       "609       5.0   NaN   NaN   NaN   NaN   5.0   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "movieId  9714  9715  9716  9717  9718  9719  9720  9721  9722  9723  \n",
       "userId                                                               \n",
       "0         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "605       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "606       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "607       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "608       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "609       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[610 rows x 9724 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TOFILL\n",
    "pivotDatased=dataset.pivot(index='userId', columns='movieId', values='rating')\n",
    "pivotDatased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating user1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the ratings of user 1. To do so, use the *movies.csv* file and your `movie_ids_map` dictionnary to find the movie title from the new movie indexes, and print the real movie title associated to each rating of user 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1</td>\n",
       "      <td>7137</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1445714974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1</td>\n",
       "      <td>8491</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1445715276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1</td>\n",
       "      <td>8287</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1445714966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating   timestamp\n",
       "243       1     7137     3.0  1445714974\n",
       "257       1     8491     2.0  1445715276\n",
       "254       1     8287     5.0  1445714966"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the ratting of user 1\n",
    "user1Ratings=dataset[dataset.userId.eq(1)]\n",
    "display (user1Ratings.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movies(data_path, movie_ids_map):\n",
    "    \"\"\"\n",
    "    return a Panda DF with all movies defined in the dictionary\n",
    "    \"\"\"\n",
    "    # read movies files [movieId,\ttitle,\tgenres]\n",
    "    movies= pd.read_csv(data_path, delimiter=',') # userId,movieId,rating,timestamp\n",
    "\n",
    "    # only keep the movies that were already ranked\n",
    "    movies= movies[movies['movieId'].isin(movie_ids_map.keys())]\n",
    "\n",
    "    # update index of users with new movie id\n",
    "    movies['movieId'] = movies['movieId'].map(movie_ids_map)\n",
    "    \n",
    "    # change indexs\n",
    "    #movies.reset_index(names=['old_index'],inplace=True)\n",
    "    #movies.set_index(keys=movies.movieId, inplace=True)\n",
    "    \n",
    "    display (movies.info())\n",
    "\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9724 entries, 0 to 9741\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  9724 non-null   int64 \n",
      " 1   title    9724 non-null   object\n",
      " 2   genres   9724 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 303.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TOFILL\n",
    "movies_s_path =  ml_latest_small_path+'movies.csv'\n",
    "movies= get_movies(movies_s_path, movie_ids_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movieId_mov</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1</td>\n",
       "      <td>7137</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1445714974</td>\n",
       "      <td>7137</td>\n",
       "      <td>Zombieland (2009)</td>\n",
       "      <td>Action|Comedy|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1</td>\n",
       "      <td>8491</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1445715276</td>\n",
       "      <td>8491</td>\n",
       "      <td>The Drop (2014)</td>\n",
       "      <td>Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1</td>\n",
       "      <td>8287</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1445714966</td>\n",
       "      <td>8287</td>\n",
       "      <td>Wolf of Wall Street, The (2013)</td>\n",
       "      <td>Comedy|Crime|Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating   timestamp  movieId_mov  \\\n",
       "243       1     7137     3.0  1445714974         7137   \n",
       "257       1     8491     2.0  1445715276         8491   \n",
       "254       1     8287     5.0  1445714966         8287   \n",
       "\n",
       "                               title                genres  \n",
       "243                Zombieland (2009)  Action|Comedy|Horror  \n",
       "257                  The Drop (2014)  Crime|Drama|Thriller  \n",
       "254  Wolf of Wall Street, The (2013)    Comedy|Crime|Drama  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using join\n",
    "display(user1Ratings.join(other=movies.set_index(keys=movies.movieId), \n",
    "                                           on=['movieId'], rsuffix = '_mov').head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7137</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1445714974</td>\n",
       "      <td>Zombieland (2009)</td>\n",
       "      <td>Action|Comedy|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8491</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1445715276</td>\n",
       "      <td>The Drop (2014)</td>\n",
       "      <td>Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8287</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1445714966</td>\n",
       "      <td>Wolf of Wall Street, The (2013)</td>\n",
       "      <td>Comedy|Crime|Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp                            title  \\\n",
       "0       1     7137     3.0  1445714974                Zombieland (2009)   \n",
       "1       1     8491     2.0  1445715276                  The Drop (2014)   \n",
       "2       1     8287     5.0  1445714966  Wolf of Wall Street, The (2013)   \n",
       "\n",
       "                 genres  \n",
       "0  Action|Comedy|Horror  \n",
       "1  Crime|Drama|Thriller  \n",
       "2    Comedy|Crime|Drama  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using merge\n",
    "display(user1Ratings.merge(right=movies, left_on='movieId', right_on='movieId').head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29 entries, 243 to 252\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   userId       29 non-null     int64  \n",
      " 1   movieId      29 non-null     int64  \n",
      " 2   rating       29 non-null     float64\n",
      " 3   timestamp    29 non-null     int64  \n",
      " 4   movieId_mov  29 non-null     int64  \n",
      " 5   title        29 non-null     object \n",
      " 6   genres       29 non-null     object \n",
      "dtypes: float64(1), int64(4), object(2)\n",
      "memory usage: 1.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movieId_mov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6540.517241</td>\n",
       "      <td>3.948276</td>\n",
       "      <td>1.445715e+09</td>\n",
       "      <td>6540.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2429.218946</td>\n",
       "      <td>0.805615</td>\n",
       "      <td>1.501627e+02</td>\n",
       "      <td>2429.218946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.445715e+09</td>\n",
       "      <td>277.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6298.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.445715e+09</td>\n",
       "      <td>6298.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7355.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.445715e+09</td>\n",
       "      <td>7355.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8045.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.445715e+09</td>\n",
       "      <td>8045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8810.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.445715e+09</td>\n",
       "      <td>8810.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId      movieId     rating     timestamp  movieId_mov\n",
       "count    29.0    29.000000  29.000000  2.900000e+01    29.000000\n",
       "mean      1.0  6540.517241   3.948276  1.445715e+09  6540.517241\n",
       "std       0.0  2429.218946   0.805615  1.501627e+02  2429.218946\n",
       "min       1.0   277.000000   2.000000  1.445715e+09   277.000000\n",
       "25%       1.0  6298.000000   3.500000  1.445715e+09  6298.000000\n",
       "50%       1.0  7355.000000   4.000000  1.445715e+09  7355.000000\n",
       "75%       1.0  8045.000000   4.500000  1.445715e+09  8045.000000\n",
       "max       1.0  8810.000000   5.000000  1.445715e+09  8810.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movieId_mov</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1445714835</td>\n",
       "      <td>277</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>291</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1445715029</td>\n",
       "      <td>291</td>\n",
       "      <td>Tommy Boy (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>1283</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1445715228</td>\n",
       "      <td>1283</td>\n",
       "      <td>Good Will Hunting (1997)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>2670</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1445714885</td>\n",
       "      <td>2670</td>\n",
       "      <td>Gladiator (2000)</td>\n",
       "      <td>Action|Adventure|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>4607</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1445714952</td>\n",
       "      <td>4607</td>\n",
       "      <td>Kill Bill: Vol. 1 (2003)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>5294</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1445714960</td>\n",
       "      <td>5294</td>\n",
       "      <td>Collateral (2004)</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>6236</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1445715013</td>\n",
       "      <td>6236</td>\n",
       "      <td>Talladega Nights: The Ballad of Ricky Bobby (2...</td>\n",
       "      <td>Action|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>6298</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1445715064</td>\n",
       "      <td>6298</td>\n",
       "      <td>Departed, The (2006)</td>\n",
       "      <td>Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>6693</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1445715141</td>\n",
       "      <td>6693</td>\n",
       "      <td>Dark Knight, The (2008)</td>\n",
       "      <td>Action|Crime|Drama|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>6784</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1445714980</td>\n",
       "      <td>6784</td>\n",
       "      <td>Step Brothers (2008)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>6993</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1445715154</td>\n",
       "      <td>6993</td>\n",
       "      <td>Inglourious Basterds (2009)</td>\n",
       "      <td>Action|Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>7137</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1445714974</td>\n",
       "      <td>7137</td>\n",
       "      <td>Zombieland (2009)</td>\n",
       "      <td>Action|Comedy|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "      <td>7241</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1445714926</td>\n",
       "      <td>7241</td>\n",
       "      <td>Shutter Island (2010)</td>\n",
       "      <td>Drama|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>7306</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1445714941</td>\n",
       "      <td>7306</td>\n",
       "      <td>Exit Through the Gift Shop (2010)</td>\n",
       "      <td>Comedy|Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>7355</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1445714841</td>\n",
       "      <td>7355</td>\n",
       "      <td>Inception (2010)</td>\n",
       "      <td>Action|Crime|Drama|Mystery|Sci-Fi|Thriller|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>7398</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1445715340</td>\n",
       "      <td>7398</td>\n",
       "      <td>Town, The (2010)</td>\n",
       "      <td>Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>7419</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1445715172</td>\n",
       "      <td>7419</td>\n",
       "      <td>Inside Job (2010)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>7572</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1445715166</td>\n",
       "      <td>7572</td>\n",
       "      <td>Louis C.K.: Hilarious (2010)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>7679</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1445715189</td>\n",
       "      <td>7679</td>\n",
       "      <td>Warrior (2011)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "      <td>7750</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1445714891</td>\n",
       "      <td>7750</td>\n",
       "      <td>Dark Knight Rises, The (2012)</td>\n",
       "      <td>Action|Adventure|Crime|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>7758</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1445714938</td>\n",
       "      <td>7758</td>\n",
       "      <td>Girl with the Dragon Tattoo, The (2011)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>253</td>\n",
       "      <td>1</td>\n",
       "      <td>8045</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1445714874</td>\n",
       "      <td>8045</td>\n",
       "      <td>Django Unchained (2012)</td>\n",
       "      <td>Action|Drama|Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>8287</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1445714966</td>\n",
       "      <td>8287</td>\n",
       "      <td>Wolf of Wall Street, The (2013)</td>\n",
       "      <td>Comedy|Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>8358</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1445715145</td>\n",
       "      <td>8358</td>\n",
       "      <td>Interstellar (2014)</td>\n",
       "      <td>Sci-Fi|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>8448</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1445714882</td>\n",
       "      <td>8448</td>\n",
       "      <td>Whiplash (2014)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>8491</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1445715276</td>\n",
       "      <td>8491</td>\n",
       "      <td>The Drop (2014)</td>\n",
       "      <td>Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>8532</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1445714854</td>\n",
       "      <td>8532</td>\n",
       "      <td>Ex Machina (2015)</td>\n",
       "      <td>Drama|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>8663</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1445715272</td>\n",
       "      <td>8663</td>\n",
       "      <td>Mad Max: Fury Road (2015)</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>8810</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1445714851</td>\n",
       "      <td>8810</td>\n",
       "      <td>The Jinx: The Life and Deaths of Robert Durst ...</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  userId  movieId  rating   timestamp  movieId_mov  \\\n",
       "0     232       1      277     3.0  1445714835          277   \n",
       "1     233       1      291     4.0  1445715029          291   \n",
       "2     234       1     1283     4.5  1445715228         1283   \n",
       "3     235       1     2670     4.0  1445714885         2670   \n",
       "4     236       1     4607     4.0  1445714952         4607   \n",
       "5     237       1     5294     3.5  1445714960         5294   \n",
       "6     238       1     6236     4.0  1445715013         6236   \n",
       "7     239       1     6298     4.0  1445715064         6298   \n",
       "8     240       1     6693     4.5  1445715141         6693   \n",
       "9     241       1     6784     5.0  1445714980         6784   \n",
       "10    242       1     6993     4.5  1445715154         6993   \n",
       "11    243       1     7137     3.0  1445714974         7137   \n",
       "12    244       1     7241     4.0  1445714926         7241   \n",
       "13    245       1     7306     3.0  1445714941         7306   \n",
       "14    246       1     7355     4.0  1445714841         7355   \n",
       "15    247       1     7398     4.5  1445715340         7398   \n",
       "16    248       1     7419     5.0  1445715172         7419   \n",
       "17    249       1     7572     4.0  1445715166         7572   \n",
       "18    250       1     7679     5.0  1445715189         7679   \n",
       "19    251       1     7750     3.5  1445714891         7750   \n",
       "20    252       1     7758     2.5  1445714938         7758   \n",
       "21    253       1     8045     3.5  1445714874         8045   \n",
       "22    254       1     8287     5.0  1445714966         8287   \n",
       "23    255       1     8358     3.0  1445715145         8358   \n",
       "24    256       1     8448     4.0  1445714882         8448   \n",
       "25    257       1     8491     2.0  1445715276         8491   \n",
       "26    258       1     8532     3.5  1445714854         8532   \n",
       "27    259       1     8663     5.0  1445715272         8663   \n",
       "28    260       1     8810     5.0  1445714851         8810   \n",
       "\n",
       "                                                title  \\\n",
       "0                    Shawshank Redemption, The (1994)   \n",
       "1                                    Tommy Boy (1995)   \n",
       "2                            Good Will Hunting (1997)   \n",
       "3                                    Gladiator (2000)   \n",
       "4                            Kill Bill: Vol. 1 (2003)   \n",
       "5                                   Collateral (2004)   \n",
       "6   Talladega Nights: The Ballad of Ricky Bobby (2...   \n",
       "7                                Departed, The (2006)   \n",
       "8                             Dark Knight, The (2008)   \n",
       "9                                Step Brothers (2008)   \n",
       "10                        Inglourious Basterds (2009)   \n",
       "11                                  Zombieland (2009)   \n",
       "12                              Shutter Island (2010)   \n",
       "13                  Exit Through the Gift Shop (2010)   \n",
       "14                                   Inception (2010)   \n",
       "15                                   Town, The (2010)   \n",
       "16                                  Inside Job (2010)   \n",
       "17                       Louis C.K.: Hilarious (2010)   \n",
       "18                                     Warrior (2011)   \n",
       "19                      Dark Knight Rises, The (2012)   \n",
       "20            Girl with the Dragon Tattoo, The (2011)   \n",
       "21                            Django Unchained (2012)   \n",
       "22                    Wolf of Wall Street, The (2013)   \n",
       "23                                Interstellar (2014)   \n",
       "24                                    Whiplash (2014)   \n",
       "25                                    The Drop (2014)   \n",
       "26                                  Ex Machina (2015)   \n",
       "27                          Mad Max: Fury Road (2015)   \n",
       "28  The Jinx: The Life and Deaths of Robert Durst ...   \n",
       "\n",
       "                                             genres  \n",
       "0                                       Crime|Drama  \n",
       "1                                            Comedy  \n",
       "2                                     Drama|Romance  \n",
       "3                            Action|Adventure|Drama  \n",
       "4                             Action|Crime|Thriller  \n",
       "5                       Action|Crime|Drama|Thriller  \n",
       "6                                     Action|Comedy  \n",
       "7                              Crime|Drama|Thriller  \n",
       "8                           Action|Crime|Drama|IMAX  \n",
       "9                                            Comedy  \n",
       "10                                 Action|Drama|War  \n",
       "11                             Action|Comedy|Horror  \n",
       "12                           Drama|Mystery|Thriller  \n",
       "13                               Comedy|Documentary  \n",
       "14  Action|Crime|Drama|Mystery|Sci-Fi|Thriller|IMAX  \n",
       "15                             Crime|Drama|Thriller  \n",
       "16                                      Documentary  \n",
       "17                                           Comedy  \n",
       "18                                            Drama  \n",
       "19                      Action|Adventure|Crime|IMAX  \n",
       "20                                   Drama|Thriller  \n",
       "21                             Action|Drama|Western  \n",
       "22                               Comedy|Crime|Drama  \n",
       "23                                      Sci-Fi|IMAX  \n",
       "24                                            Drama  \n",
       "25                             Crime|Drama|Thriller  \n",
       "26                            Drama|Sci-Fi|Thriller  \n",
       "27                 Action|Adventure|Sci-Fi|Thriller  \n",
       "28                                      Documentary  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the ratting with titles of user 1\n",
    "user1RatingsWithTitles=(user1Ratings.join(other=movies.set_index(keys=movies.movieId), on=['movieId'], rsuffix = '_mov'))\n",
    "                        #.loc[:,['userId', 'movieId', 'rating', 'title', 'genres']])\n",
    "display(user1RatingsWithTitles.info())\n",
    "display(user1RatingsWithTitles.describe())\n",
    "user1RatingsWithTitles\n",
    "display(user1RatingsWithTitles.sort_values(by=['movieId']).reset_index())#, axes=0, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a python library made for easily designing complex models such as deep learning models, in this module we are going to use just a few features from it to implement our simple matrix factorization model, as it makes a good introduction to the library before the next module about deep learning where you will also be using Keras.\n",
    "\n",
    "The following function `get_mf_model` implements the model described in equation (2) in Koren's paper (without the $+\\lambda(\\ldots)$ part for the moment). So it basically tries to find the $p_u \\in \\mathbb{R}^k$ and $q_i \\in \\mathbb{R}^k$ vectors that minimizes the squared loss between their dot product $p_u^Tq_i$, and the observed ratings $r_{ui}$, from random initialization of $p_u$ and $q_i$. In machine learning terms, $p_u$ and $q_i$ are called the *embeddings* of the user $u$ and of the movie $i$ respectively. Their size $k$ is an hyper-parameter of the model, which is called the *rank* of the factorization.\n",
    "\n",
    "To do so, it uses the functional API from Keras (the other API proposed is the sequential one, but is not adapted for this model), you can read about it here : https://keras.io/guides/functional_api/ .\n",
    "\n",
    "Keras, unlike Numpy, uses a different progamming paradigm. Numpy uses an *imperative* programming style (like python in general), meaning that when you execute `x.dot(y)`, the dot product is actually calculated. Keras however, uses a *declarative* (also called *symbolic*) programming style, meaning that when you write `Dot()([x, y])`, you tell Keras than when you will call the *fit* function of your model in the future, you will want to do a dot product between the future values that *x* and *y* will have. And this is what Keras is about, it allows you to build your own model as a sequence of operations, describing each input and output, and then later fit it and predict with it.\n",
    "\n",
    "Let's not get in too many details, but retain that the `get_mf_model` function below is not actually executing the model, it creates it, and returns an object of the class `keras.models.Model` that has been instructed with your model operations, and this object can then be trained with the classic `fit` and `predict` functions. \n",
    "\n",
    "Read carefully the comments in the code of the function to understand the different steps in the model creation process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My note:\n",
    "\n",
    "A BASIC MATRIX FACTORIZATION MODEL\n",
    "\n",
    "- Matrix factorization models map both users and items to a joint latent factor space of dimensionality $f$\n",
    " such that user-item interactions are modeled as inner products in that space.\n",
    "-  Accordingly, each item $i$ is associated with a vector $q_i ∈ \\mathbb{R} ^f$,\n",
    " and each user $u$ is associated with a vector $p_u \\in \\mathbb{R} ^f$. \n",
    "For a given item $i$, the elements of $q_i$ measure the extent to which the item possesses those factors, positive or negative.\n",
    "\n",
    "- For a given user $u$, the elements of $p_u$ measure the extent of interest the user has in items that are high\n",
    "on the corresponding factors, again, positive or negative. \n",
    "The resulting dot product, $q_i^T p_u$, captures the interaction between user $u$ and item $i$—the user’s overall interest in the item’s characteristics.\n",
    "This approximates user $u$’s rating of item $i$, which is denoted by $r_{ui}$, leading to the estimate\n",
    "$$\\widehat{r} _{ui} = q_i^T p_u \\quad\\text{(1)}$$\n",
    "\n",
    "- The major challenge is computing the mapping of each item and user to factor vectors\n",
    "$q_i$, $p_u \\in  \\mathbb{R} ^f$. \n",
    "After the recommender system completes this mapping, it can easily estimate the rating a user will give to any item\n",
    "by using Equation 1. \n",
    "\n",
    "- Such a model is closely related to *singular value decomposition* (SVD), a well-established technique for identifying latent semantic factors in information retrieval. Applying SVD in the collaborative filtering domain requires factoring the user-item rating matrix\n",
    "\n",
    "\n",
    "\n",
    "-  To learn the factor vectors \n",
    "$(p_u  \\text{ and }  q_i  )$\n",
    ", the system\n",
    "minimizes the lambda_ularized squared error on the set of\n",
    "known ratings\n",
    " $$ \\to {min}_{q*, p*} \\sum_{(u,i)∈κ} (r_{ui} - \\mathrm{q}_{i}^{T}p_{u})^{2}  + λ(\\left\\| q_i \\right\\|^{2} + \\left\\| p_u \\right\\|^2)\\quad\\text{(2)}$$\n",
    "\n",
    " - Here, $κ$ is the set of the $(u,i)$ pairs for which $r_{ui}$ is known (the training set). \n",
    "\n",
    "\n",
    " - -> use of https://latexeditor.lagrida.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Reshape\n",
    "from keras.layers import Dot\n",
    "\n",
    "def get_mf_model(nb_users, nb_movies, k):\n",
    "    \"\"\"\n",
    "    Build a simple matrix factorization model from\n",
    "    the number of user, the number of movies, and the size of the embeddings k.\n",
    "    \n",
    "    Input:\n",
    "        nb_users : int : The number of unique users\n",
    "        nb_movies : int : The number of unique movies\n",
    "        k : int : The size of the embeddings\n",
    "        \n",
    "    Output:\n",
    "        model : keras.models.Model : A keras model that implements matrix factorization\n",
    "        \n",
    "    \"\"\"\n",
    "    dim_embedddings = k\n",
    "    \n",
    "    #Inputs:\n",
    "    #First we describe the input of the model, that is the training data that we will give it as X\n",
    "    #In our case, the input are just the user index u and the movie index i.\n",
    "    #So we declare two inputs of size one:\n",
    "    u = Input(shape=(1,), dtype='int32', name = \"u__user_id\")\n",
    "    i = Input(shape=(1,), dtype='int32', name = 'i__movie_id')\n",
    "    \n",
    "    #Then let's declare our variable, the embeddings p and q.\n",
    "    #First with the users, we declare that we have nb_users embeddings, each of size dim_embeddings.\n",
    "    #An embedding object is indexed by calling it with the index parameter like a function,\n",
    "    #so we add a `(u)` at the end to tell keras we want it to be indexed \n",
    "    #by the user ids we will pass at training time as inputs.\n",
    "    p_u = Embedding(nb_users, dim_embedddings, name=\"p_u__user_embedding\")(u)\n",
    "    \n",
    "    #Unfortunatly, when indexing an embeddings it keeps [1,k] matrix shape instead\n",
    "    #of just a [k] vector, so we have to tell Keras that we just want a vector by\n",
    "    #redefining its shape:\n",
    "    p_u = Reshape((dim_embedddings,), name=\"p_u__user_embedding_reshaped\")(p_u)\n",
    "    \n",
    "    # Same thing for the movie embeddings:\n",
    "    q_i = Embedding(nb_movies, dim_embedddings, name=\"q_i__movie_embedding\")(i)\n",
    "    q_i = Reshape((dim_embedddings,), name=\"q_i__movie_embedding_reshaped\")(q_i)\n",
    "    \n",
    "    #Then the dot product between the two indexed embeddings, \n",
    "    #we'll understand the axes = 1 part later.\n",
    "    r_hat = Dot(axes = 1)([q_i, p_u])\n",
    "\n",
    "    #We define our model by giving its input and outputs, in our case\n",
    "    #the user and movie ids will be the inputs, and the output will be\n",
    "    #the estimated rating r_hat, that is the dot product of the \n",
    "    #corresponding embeddings.\n",
    "    model = Model(inputs=[u, i], outputs=r_hat)\n",
    "    \n",
    "    #Finally, we define the loss and metric to use, in our case the mean squared error,\n",
    "    #along with the optimization method, we'll understand what is 'adam' later also.\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[\"mse\"])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30\n",
    "mf_model = get_mf_model(nb_users, nb_movies, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras allows us to have a textual overview of the model we defined with the *summary()* function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ i__movie_id         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ u__user_id          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">291,720</span> │ i__movie_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embedding │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,300</span> │ u__user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ q_i__movie_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embeddin… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p_u__user_embedd… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ q_i__movie_embed… │\n",
       "│                     │                   │            │ p_u__user_embedd… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ i__movie_id         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ u__user_id          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m)     │    \u001b[38;5;34m291,720\u001b[0m │ i__movie_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embedding │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m)     │     \u001b[38;5;34m18,300\u001b[0m │ u__user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ q_i__movie_embed… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embeddin… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ p_u__user_embedd… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ q_i__movie_embed… │\n",
       "│                     │                   │            │ p_u__user_embedd… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,020</span> (1.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m310,020\u001b[0m (1.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,020</span> (1.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m310,020\u001b[0m (1.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(mf_model, \"my_first_model_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the keras objects we defined in our model is called a *layer*, and we find them in order in the first column. The *Param #* column gives the number of trainable parameters of the layer, in our case these are just the embeddings, and they should be equal to $nb\\_users \\times k$ and $nb\\_movies \\times k$. The *Connected to* column tells for each layer which layers are inputs for this layer (you can safely ignore the `[0][0]` for this module).\n",
    "\n",
    "Finally the *Output Shape* column gives us the shape of the layer, each layer being a *tensor*. A tensor is the generalization of matrices to more than two dimensions. So a matrix is a 2D-tensor and a vector is a 1D-tensor, and each layer can be a matrix, a vector, or a higher-order tensor. The output shape we see is indeed the expected one at each layer, except there is this `None` in first dimension, why is that ?\n",
    "\n",
    "To understand it, we have to get into how Keras is actually minimizing the mean squared loss of our model. In general, when in comes to minimizing error functions on big datasets, a generic method is to use Stocastic Gradient Descent (SGD), briefly described in page 4 of Koren's article. \n",
    "\n",
    "Read about gradient descent, SGD and its variant mini-batch SGD in Chapter 4 of *Hands on ML ...* (pages 111-120):\n",
    "https://drive.google.com/file/d/1t0rc3x5YQBgLXVLET6BzR4jn5vzMI_m0/view?usp=sharing\n",
    "\n",
    "- Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (V2) p 118 <148>\n",
    "\n",
    "\n",
    "This is what Keras does when it fits the model, it initializes the $q_i$ and $p_u$ embedding vectors randomly, and then perform mini-batch SGD to find the minimum mean squared error on the training set. Since mini-batching means considering multiple training samples at the same time, Keras keeps the first dimension of each layer to stack the samples of each batch, this is why `None` is written, the actual batch_size being set at training time when calling the `fit` function. This is also why we had to set `axes=1` when calling the `Dot` layer in the `get_mf_model` function, because the first dimension (axe 0) of each layer is kept for the batches. And about the `optimizer='adam'`, it is just a variation of mini-batch SGD that is faster, we'll get into more details about SGD variations in the optional parts of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally train our matrix factorization model on our movieLens data. The `epochs` parameter controls the number of iterations of the SGD algorithm, that is the number of times it is going to pass on each training rating and update the embeddings accordingly. Let's keep it at 20 for the moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 13.3386 - mse: 13.3386\n",
      "Epoch 2/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 12.1829 - mse: 12.1829\n",
      "Epoch 3/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.1910 - mse: 5.1910\n",
      "Epoch 4/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 2.5253 - mse: 2.5253\n",
      "Epoch 5/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.7239 - mse: 1.7239\n",
      "Epoch 6/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3326 - mse: 1.3326\n",
      "Epoch 7/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1212 - mse: 1.1212\n",
      "Epoch 8/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9632 - mse: 0.9632\n",
      "Epoch 9/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.8720 - mse: 0.8720\n",
      "Epoch 10/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7962 - mse: 0.7962\n",
      "Epoch 11/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7480 - mse: 0.7480\n",
      "Epoch 12/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.6995 - mse: 0.6995\n",
      "Epoch 13/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6686 - mse: 0.6686\n",
      "Epoch 14/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.6403 - mse: 0.6403\n",
      "Epoch 15/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.6167 - mse: 0.6167\n",
      "Epoch 16/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6000 - mse: 0.6000\n",
      "Epoch 17/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5827 - mse: 0.5827\n",
      "Epoch 18/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5619 - mse: 0.5619\n",
      "Epoch 19/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5580 - mse: 0.5580\n",
      "Epoch 20/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5373 - mse: 0.5373\n"
     ]
    }
   ],
   "source": [
    "history = mf_model.fit(X_train, y_train, epochs=20, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_model.save(model_path + \"mf_model.keras\")\n",
    "#mf_model=keras.models.load_model(model_path + \"mf_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can now try to predict the test ratings, and report our root mean squared error like in other regression problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      " Test RMSE : 1.0737200895147418 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "y_pred = mf_model.predict(X_test)\n",
    "\n",
    "test_rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\" Test RMSE : %s \" % test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get about 1.1/1.2 RMSE, we can probably do better !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding user and movie bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's enhance our matrix factorization model and add the user and movie biases to the rating estimation function as in equation (4) of Koren's paper ; except we will for the moment forget about the global bias $\\mu$ as it is not so intuitive to implement in Keras. Fill the function below to do so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My notes:\n",
    "- https://medium.com/@yashsonar213/how-to-build-a-recommendation-systems-matrix-factorization-using-keras-778931cc666f\n",
    "- user & movie biais is\n",
    "$$ b_{ui}= \\mu + b_u +b_i$$\n",
    "\n",
    "- rating with biais:\n",
    "$$ \\widehat{r} =\\mu + b_u + b_i + q_i^Tp_u $$\n",
    "\n",
    "- with chatGPT:\n",
    "with this keras model defined in get_mf_bias_model function I want to add the u and i biais.\n",
    "Can you help me?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Add\n",
    "\n",
    "def get_mf_bias_model(nb_users, nb_movies, k):\n",
    "    \"\"\"\n",
    "    Build a smatrix factorization model with user and movie biases\n",
    "    \n",
    "    Input:\n",
    "        nb_users : int : The number of unique users\n",
    "        nb_movies : int : The number of unique movies\n",
    "        k : int : The size of the embeddings\n",
    "        \n",
    "    Output:\n",
    "        model : keras.models.Model : A keras model that implements matrix factorization with biases\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    dim_embedddings = k\n",
    "    \n",
    "    # User embeddings\n",
    "    u = Input(shape=(1,), dtype='int32', name = 'u__user_id')\n",
    "    p_u = Embedding(nb_users, dim_embedddings, name=\"p_u__user_embedding\")(u)\n",
    "    p_u = Reshape((dim_embedddings,), name=\"p_u__user_embedding_reshaped\")(p_u)\n",
    "    \n",
    "    # Movie embeddings\n",
    "    i = Input(shape=(1,), dtype='int32', name = 'i__movie_id')\n",
    "    q_i = Embedding(nb_movies, dim_embedddings, name=\"q_i__movie_embedding\")(i)\n",
    "    q_i = Reshape((dim_embedddings,), name=\"q_i__movie_embedding_reshaped\")(q_i)\n",
    "    \n",
    "    # Dot product of user and item embeddings\n",
    "    d = Dot(axes=1, name='dot_user_item')([p_u, q_i])\n",
    "\n",
    "    #TOFILL\n",
    "    # User and item bias embeddings (1-dimensional)\n",
    "    b_u = Embedding(nb_users, 1, name='b_u__user_bias')(u)\n",
    "    b_u = Reshape((1,), name='b_u__user_bias_reshaped')(b_u)\n",
    "    \n",
    "    b_i = Embedding(nb_movies, 1, name='b_i__item_bias')(i)\n",
    "    b_i = Reshape((1,), name='b_i__item_bias_reshaped')(b_i)\n",
    "\n",
    "    # Final prediction: dot + user bias + item bias\n",
    "    r_hat = Add(name='r_hat')([d, b_u, b_i])\n",
    "    # Build and compile the model\n",
    "    model = Model(inputs=[u, i], outputs=r_hat)\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_bias_model = get_mf_bias_model(nb_users, nb_movies, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ u__user_id          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ i__movie_id         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embedding │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,300</span> │ u__user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">291,720</span> │ i__movie_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embeddin… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p_u__user_embedd… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ q_i__movie_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_u__user_bias      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ u__user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_i__item_bias      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,724</span> │ i__movie_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_user_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p_u__user_embedd… │\n",
       "│                     │                   │            │ q_i__movie_embed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_u__user_bias_res… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ b_u__user_bias[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_i__item_bias_res… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ b_i__item_bias[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ r_hat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_user_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ b_u__user_bias_r… │\n",
       "│                     │                   │            │ b_i__item_bias_r… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ u__user_id          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ i__movie_id         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embedding │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m)     │     \u001b[38;5;34m18,300\u001b[0m │ u__user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m)     │    \u001b[38;5;34m291,720\u001b[0m │ i__movie_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embeddin… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ p_u__user_embedd… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ q_i__movie_embed… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_u__user_bias      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │        \u001b[38;5;34m610\u001b[0m │ u__user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_i__item_bias      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │      \u001b[38;5;34m9,724\u001b[0m │ i__movie_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_user_item (\u001b[38;5;33mDot\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ p_u__user_embedd… │\n",
       "│                     │                   │            │ q_i__movie_embed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_u__user_bias_res… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ b_u__user_bias[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_i__item_bias_res… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ b_i__item_bias[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ r_hat (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dot_user_item[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ b_u__user_bias_r… │\n",
       "│                     │                   │            │ b_i__item_bias_r… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,354</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,354\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,354</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,354\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf_bias_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 12.7470 - mse: 12.7470\n",
      "Epoch 2/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 9.8182 - mse: 9.8182\n",
      "Epoch 3/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.0061 - mse: 4.0061\n",
      "Epoch 4/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.9978 - mse: 1.9978\n",
      "Epoch 5/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.3722 - mse: 1.3722\n",
      "Epoch 6/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.0849 - mse: 1.0849\n",
      "Epoch 7/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.9193 - mse: 0.9193\n",
      "Epoch 8/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.8120 - mse: 0.8120\n",
      "Epoch 9/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7352 - mse: 0.7352\n",
      "Epoch 10/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.6792 - mse: 0.6792\n",
      "Epoch 11/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.6280 - mse: 0.6280\n",
      "Epoch 12/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.6030 - mse: 0.6030\n",
      "Epoch 13/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.5717 - mse: 0.5717\n",
      "Epoch 14/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.5499 - mse: 0.5499\n",
      "Epoch 15/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.5302 - mse: 0.5302\n",
      "Epoch 16/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.5180 - mse: 0.5180\n",
      "Epoch 17/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.5043 - mse: 0.5043\n",
      "Epoch 18/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.4865 - mse: 0.4865\n",
      "Epoch 19/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.4716 - mse: 0.4716\n",
      "Epoch 20/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.4603 - mse: 0.4603\n"
     ]
    }
   ],
   "source": [
    "history = mf_bias_model.fit(X_train, y_train, epochs=20, batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_bias_model.save(model_path + \"mf_bias_model.keras\")\n",
    "#mf_bias_model=keras.models.load_model(model_path + \"mf_bias_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      " Test RMSE : 0.9789416903486807 \n"
     ]
    }
   ],
   "source": [
    "y_pred = mf_bias_model.predict(X_test)\n",
    "test_rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\" Test RMSE : %s \" % test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a lower RMSE, about 1.0/1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the moment we have omitted the regularization of the embeddings and bias parameters, as described in equation (5) of Koren's paper. We are now going to add them to the model, have a look at https://keras.io/layers/embeddings/ and https://keras.io/regularizers/ to see how to do this with keras. Fill the function below to implement it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "- from le chat\n",
    "\n",
    "To add L2 regularization to your model, you should apply it to the embedding layers (both the latent factors and the biases).\n",
    "\n",
    "In Keras, this is done using kernel_regularizer=l2(λ) in the Embedding layers, where λ is your regularization strength (e.g. 1e-6 or 0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def get_mf_bias_l2_reg_model(nb_users, nb_movies, k, lambda_=1e-6):\n",
    "    \"\"\"\n",
    "    Build a smatrix factorization model with user and movie biases, and L2 regularization\n",
    "    \n",
    "    Input:\n",
    "        nb_users : int : The number of unique users\n",
    "        nb_movies : int : The number of unique movies\n",
    "        k : int : The size of the embeddings\n",
    "        \n",
    "    Output:\n",
    "        model : keras.models.Model : A keras model that implements matrix factorization with biases\n",
    "            and L2 regularization\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #TOFILL\n",
    "     # Inputs\n",
    "    u = Input(shape=(1,), dtype='int32', name='u__user_id')\n",
    "    i = Input(shape=(1,), dtype='int32', name='i__movie_id')\n",
    "    \n",
    "    # Embeddings with L2 regularization\n",
    "    p_u = Embedding(nb_users, k, name='p_u__user_embedding',\n",
    "                    embeddings_regularizer=l2(lambda_))(u)\n",
    "    p_u = Reshape((k,), name='p_u__user_embedding_reshaped')(p_u)\n",
    "\n",
    "    q_i = Embedding(nb_movies, k, name='q_i__movie_embedding',\n",
    "                    embeddings_regularizer=l2(lambda_))(i)\n",
    "    q_i = Reshape((k,), name='q_i__movie_embedding_reshaped')(q_i)\n",
    "\n",
    "    # Bias embeddings with L2 regularization\n",
    "    b_u = Embedding(nb_users, 1, name='b_u__user_bias',\n",
    "                    embeddings_regularizer=l2(lambda_))(u)\n",
    "    b_u = Reshape((1,), name='b_u__user_bias_reshaped')(b_u)\n",
    "\n",
    "    b_i = Embedding(nb_movies, 1, name='b_i__item_bias',\n",
    "                    embeddings_regularizer=l2(lambda_))(i)\n",
    "    b_i = Reshape((1,), name='b_i__item_bias_reshaped')(b_i)\n",
    "    \n",
    "    # Dot product\n",
    "    d = Dot(axes=1, name='dot_user_item')([p_u, q_i])\n",
    "    \n",
    "    # Final prediction\n",
    "    r_hat = Add(name='r_hat')([d, b_u, b_i])\n",
    "    \n",
    "    # Model\n",
    "    model = Model(inputs=[u, i], outputs=r_hat)\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "   \n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.00001\n",
    "mf_bias_l2_reg_model = get_mf_bias_l2_reg_model(nb_users, nb_movies, k, lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_bias_l2_reg_model.save(model_path + \"mf_bias_l2_reg_model.keras\")\n",
    "#mf_bias_l2_reg_model=keras.models.load_model(model_path + \"mf_bias_l2_reg_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ u__user_id          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ i__movie_id         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embedding │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,300</span> │ u__user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">291,720</span> │ i__movie_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embeddin… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p_u__user_embedd… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ q_i__movie_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_u__user_bias      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ u__user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_i__item_bias      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,724</span> │ i__movie_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_user_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p_u__user_embedd… │\n",
       "│                     │                   │            │ q_i__movie_embed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_u__user_bias_res… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ b_u__user_bias[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_i__item_bias_res… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ b_i__item_bias[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ r_hat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_user_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ b_u__user_bias_r… │\n",
       "│                     │                   │            │ b_i__item_bias_r… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ u__user_id          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ i__movie_id         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embedding │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m)     │     \u001b[38;5;34m18,300\u001b[0m │ u__user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m)     │    \u001b[38;5;34m291,720\u001b[0m │ i__movie_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p_u__user_embeddin… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ p_u__user_embedd… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ q_i__movie_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ q_i__movie_embed… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_u__user_bias      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │        \u001b[38;5;34m610\u001b[0m │ u__user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_i__item_bias      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │      \u001b[38;5;34m9,724\u001b[0m │ i__movie_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_user_item (\u001b[38;5;33mDot\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ p_u__user_embedd… │\n",
       "│                     │                   │            │ q_i__movie_embed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_u__user_bias_res… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ b_u__user_bias[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ b_i__item_bias_res… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ b_i__item_bias[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ r_hat (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dot_user_item[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ b_u__user_bias_r… │\n",
       "│                     │                   │            │ b_i__item_bias_r… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,354</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,354\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,354</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,354\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf_bias_l2_reg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 13.0225 - mse: 13.0207\n",
      "Epoch 2/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 10.9444 - mse: 10.9403\n",
      "Epoch 3/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.2377 - mse: 5.2124\n",
      "Epoch 4/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 2.3117 - mse: 2.2596\n",
      "Epoch 5/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.5827 - mse: 1.5139\n",
      "Epoch 6/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.2687 - mse: 1.1877\n",
      "Epoch 7/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 1.1046 - mse: 1.0141\n",
      "Epoch 8/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.9866 - mse: 0.8884\n",
      "Epoch 9/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.9166 - mse: 0.8119\n",
      "Epoch 10/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8724 - mse: 0.7625\n",
      "Epoch 11/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.8297 - mse: 0.7153\n",
      "Epoch 12/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.8077 - mse: 0.6897\n",
      "Epoch 13/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7821 - mse: 0.6610\n",
      "Epoch 14/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7718 - mse: 0.6480\n",
      "Epoch 15/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7514 - mse: 0.6254\n",
      "Epoch 16/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7420 - mse: 0.6141\n",
      "Epoch 17/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.7341 - mse: 0.6046\n",
      "Epoch 18/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7248 - mse: 0.5939\n",
      "Epoch 19/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7073 - mse: 0.5752\n",
      "Epoch 20/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.6991 - mse: 0.5659\n"
     ]
    }
   ],
   "source": [
    "history = mf_bias_l2_reg_model.fit(X_train, y_train, epochs=20, batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_bias_l2_reg_model.save(model_path + \"mf_bias_l2_reg_model.keras\")\n",
    "#mf_bias_l2_reg_model=keras.models.load_model(model_path + \"mf_bias_l2_reg_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      " Test RMSE : 1.0135045372739868 \n"
     ]
    }
   ],
   "source": [
    "y_pred = mf_bias_l2_reg_model.predict(X_test)\n",
    "test_rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\" Test RMSE : %s \" % test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might get a slightly worse (higher) RMSE, because adding regularization makes the optimization process more complex, and it probably requires more than 20 epochs to properly converge. But in the end its gonna yield better results with more iterations, so let's change this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of setting manually the maximum number of epochs, we prefer to use *early stopping*. When training with early stopping, keras keeps a given validation set though the parameter `validation_split`, on which it is going to monitor a performance measure you give it (here the `mse`) at every epoch, and continue optimization while the mse on the validation set keeps going down, and stops it when it goes back up. This mechanism is an easy way to avoid over-fitting, you can read more about it there : https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "\n",
    "In general when using early stopping we setup a high number of maximum epochs, that is never reach because the optimization is stopped by early stopping first :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 13.0529 - mse: 13.0510 - val_loss: 11.9593 - val_mse: 11.9575\n",
      "Epoch 2/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 11.3817 - mse: 11.3787 - val_loss: 8.1795 - val_mse: 8.1675\n",
      "Epoch 3/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.6754 - mse: 6.6574 - val_loss: 3.5337 - val_mse: 3.4958\n",
      "Epoch 4/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 2.8488 - mse: 2.8051 - val_loss: 2.2398 - val_mse: 2.1817\n",
      "Epoch 5/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.8188 - mse: 1.7570 - val_loss: 1.7906 - val_mse: 1.7190\n",
      "Epoch 6/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.4029 - mse: 1.3286 - val_loss: 1.5643 - val_mse: 1.4823\n",
      "Epoch 7/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.1817 - mse: 1.0974 - val_loss: 1.4352 - val_mse: 1.3447\n",
      "Epoch 8/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 1.0338 - mse: 0.9414 - val_loss: 1.3546 - val_mse: 1.2571\n",
      "Epoch 9/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.9495 - mse: 0.8504 - val_loss: 1.3031 - val_mse: 1.1995\n",
      "Epoch 10/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8888 - mse: 0.7840 - val_loss: 1.2692 - val_mse: 1.1607\n",
      "Epoch 11/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8373 - mse: 0.7276 - val_loss: 1.2449 - val_mse: 1.1321\n",
      "Epoch 12/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8123 - mse: 0.6985 - val_loss: 1.2292 - val_mse: 1.1126\n",
      "Epoch 13/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7806 - mse: 0.6632 - val_loss: 1.2182 - val_mse: 1.0985\n",
      "Epoch 14/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7591 - mse: 0.6387 - val_loss: 1.2090 - val_mse: 1.0866\n",
      "Epoch 15/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.7327 - mse: 0.6096 - val_loss: 1.2046 - val_mse: 1.0798\n",
      "Epoch 16/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7191 - mse: 0.5938 - val_loss: 1.1990 - val_mse: 1.0722\n",
      "Epoch 17/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6947 - mse: 0.5675 - val_loss: 1.1970 - val_mse: 1.0683\n",
      "Epoch 18/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6883 - mse: 0.5593 - val_loss: 1.1960 - val_mse: 1.0658\n",
      "Epoch 19/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.6758 - mse: 0.5452 - val_loss: 1.1938 - val_mse: 1.0622\n",
      "Epoch 20/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.6655 - mse: 0.5336 - val_loss: 1.1921 - val_mse: 1.0594\n",
      "Epoch 21/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.6544 - mse: 0.5213 - val_loss: 1.1934 - val_mse: 1.0595\n",
      "Epoch 22/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.6378 - mse: 0.5036 - val_loss: 1.1939 - val_mse: 1.0591\n",
      "Epoch 23/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.6206 - mse: 0.4855 - val_loss: 1.1953 - val_mse: 1.0596\n",
      "Epoch 24/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.6181 - mse: 0.4823 - val_loss: 1.1960 - val_mse: 1.0595\n",
      "Epoch 25/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6051 - mse: 0.4685 - val_loss: 1.1972 - val_mse: 1.0600\n",
      "Epoch 26/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.5961 - mse: 0.4587 - val_loss: 1.1988 - val_mse: 1.0609\n",
      "Epoch 27/500\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.5815 - mse: 0.4435 - val_loss: 1.2025 - val_mse: 1.0642\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "mf_bias_l2_reg_es_model = get_mf_bias_l2_reg_model(nb_users, nb_movies, k, lambda_)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_mse', patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "## TODO ask  mode min / max\n",
    "# early_stopping = EarlyStopping(monitor='val_mse', mode='min', patience=5, verbose=1, restore_best_weights=True)\n",
    "# early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1)\n",
    "history = mf_bias_l2_reg_es_model.fit(X_train, y_train, epochs=500, batch_size=512, validation_split=0.1, \n",
    "                                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_bias_l2_reg_es_model.save(model_path + \"mf_bias_l2_reg_es_model.keras\")\n",
    "#mf_bias_l2_reg_es_model=keras.models.load_model(model_path + \"mf_bias_l2_reg_es_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the training stops before 500 epochs, when the validation MSE stops decreasing during 5 consecutive epochs (the patience value = 5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      " Test RMSE : 1.0324984147994667 \n"
     ]
    }
   ],
   "source": [
    "y_pred = mf_bias_l2_reg_es_model.predict(X_test)\n",
    "test_rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\" Test RMSE : %s \" % test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search embedding size and regularization factor with early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the moment we didn't grid search our model hyper-parameters, such as `k` and `lambda_`. There exists some scikit-learn wrappers for keras models in order to use scikit grid search functions, unfortunately they only work with single input keras models, which is not our case as we have two inputs: the user and the movie indexes.\n",
    "\n",
    "So let's implement your own grid search function for the two parameters `k` and `lambda_`. With big enough datasets, it is not necessary to do a cross-validation for each hyper-parameter combination, and we can simply split the training set into a sub-training set and a validation set to test our hyper-parameters. It does work because the validation set is big enough to see enough data variations, and with very big datasets, it is anyway not possible anymore to do a full cross-validation as it takes too much time to train. \n",
    "\n",
    "Fill in the `grid_search` function below and use early stopping with a validation split (just like above), and retrieve the validation RMSE (you can get the MSE from the `history` variable that is returned by the `fit` method (and then take the `sqrt` of that)) for all the hyper-parameter combinations from the `param_grid` dictionary of hyper-parameter values. Call the `get_model_function` parameter (yes, you can pass functions as parameters!) to generate each model, and return the hyper-parameters that give the lowest RMSE on the 10% validation set, the RMSE value, and the best corresponding trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(data, train_prop = 0.9):\n",
    "    \"\"\"\n",
    "    Build train and test sets and reindex userIds and MovieIds from 0 with contiguous indexes.\n",
    "    \n",
    "    Input: \n",
    "        data : panda data frame\n",
    "        train_prop : float : The proportion of the training set \n",
    "    \n",
    "    Output:\n",
    "        train : pandas.DataFrame : A dataframe with columns [userId, movieId, rating, timestamp], where\n",
    "            the userId and movieId value have been replaced with new ids starting at 0. \n",
    "            Contains `train_prop` random entries from the input file.\n",
    "        test : pandas.DataFrame : Same as `train`, contains the 1 - `train_prop` remaining entries.\n",
    "        nb_users : int : Number of unique user ids\n",
    "        nb_movies : int : Number of unique movie ids\n",
    "        user_ids_map : dict : A mapping of original file userId to a new index starting at 0.\n",
    "            Keys are int from the original userId column, values are int of the new indexation.\n",
    "        movie_ids_map : dict : Same as `user_ids_map` for the movieIds.\n",
    "    \"\"\"\n",
    "    \n",
    "    #TOFILL\n",
    "\n",
    "\n",
    "    # get nb users / movies\n",
    "    nb_users=  data.userId.nunique() # len(user_ids_map)\n",
    "    nb_movies= len(movie_ids_map)      # ratings.movieId.nunique()\n",
    "\n",
    "    train= data.sample(frac=train_prop, axis=0)\n",
    "    test=  data.drop(train.index)\n",
    "\n",
    "    return train, test, nb_users, nb_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def grid_search(data, param_grid, get_model_function, nb_users, nb_movies, validation_size = 0.1):\n",
    "    \"\"\"\n",
    "    Performs a grid search over the \n",
    "    \n",
    "    Input:\n",
    "        data : DataFrame : The training set to be split between training and validation sets\n",
    "        param_grid : dict : Dictionary containing the values of the hyper-parameters to grid-search\n",
    "        get_model_function : function : A function that returns the keras model to grid-search\n",
    "        nb_users : int : The number of unique users\n",
    "        nb_movies : int : The number of unique movies\n",
    "        validation_size : float : Proportion of the validation set\n",
    "        \n",
    "    Output:\n",
    "        best_params : dict : A dictionary of the best hyper-parameters values\n",
    "        best_score : float : The validation RMSE corresponding to the best\n",
    "        best_model : keras.Model : The model trained with the best hyper-parameters\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    best_score = np.inf\n",
    "    best_params = {}\n",
    "    best_model = None\n",
    "    #TOFILL\n",
    "\n",
    "    # General settings\n",
    "    base_settings = {'epochs':500, 'batch_size':512, 'validation_split':0.1, 'callbacks':[early_stopping]}\n",
    "\n",
    "    # get train / test from data dataset\n",
    "    train, test, nb_users, nb_movies = get_train_test_data(data, train_prop = 1-validation_size)\n",
    "\n",
    "    X_train = [train[\"userId\"].to_numpy(), train[\"movieId\"].to_numpy()]\n",
    "    y_train = train[\"rating\"].to_numpy()\n",
    "    \n",
    "    X_test = [test[\"userId\"].to_numpy(), test[\"movieId\"].to_numpy()]\n",
    "    y_test = test[\"rating\"].to_numpy()\n",
    "\n",
    "    data_settiings = {'x':X_train, 'y':y_train}\n",
    "\n",
    "    #print (*param_grid.values())\n",
    "    for values in itertools.product(*param_grid.values()):\n",
    "        variable_settings = dict(zip(param_grid.keys(), values))\n",
    "        settings = {**data_settiings, **base_settings}\n",
    "\n",
    "        model = get_model_function(nb_users, nb_movies, **variable_settings)\n",
    "        #model(inputs=settings)\n",
    "        \n",
    "       # model = get_model_function(inputs=settings)  #get_model_function(nb_users, nb_movies, k, lambda_)\n",
    "        model.fit(**settings)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        test_rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "        print(f\"{variable_settings} Test RMSE : {test_rmse} \")\n",
    "        if test_rmse < best_score:\n",
    "            best_score=test_rmse\n",
    "            best_params=variable_settings\n",
    "            best_model=model\n",
    "\n",
    "    return best_params, best_score, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 13.1528 - mse: 13.1399 - val_loss: 12.1943 - val_mse: 12.1862\n",
      "Epoch 2/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 11.8701 - mse: 11.8542 - val_loss: 10.1054 - val_mse: 10.0239\n",
      "Epoch 3/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 9.1970 - mse: 9.0621 - val_loss: 6.4673 - val_mse: 6.1371\n",
      "Epoch 4/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.7053 - mse: 5.3022 - val_loss: 4.3077 - val_mse: 3.6971\n",
      "Epoch 5/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.8714 - mse: 3.2046 - val_loss: 3.5563 - val_mse: 2.7430\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "{'k': 15, 'lambda_': 0.0002} Test RMSE : 3.493080614599722 \n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 13.1003 - mse: 13.0965 - val_loss: 12.1659 - val_mse: 12.1627\n",
      "Epoch 2/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 11.8514 - mse: 11.8460 - val_loss: 10.0840 - val_mse: 10.0619\n",
      "Epoch 3/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.1591 - mse: 9.1239 - val_loss: 6.3293 - val_mse: 6.2439\n",
      "Epoch 4/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.4359 - mse: 5.3304 - val_loss: 3.7358 - val_mse: 3.5701\n",
      "Epoch 5/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.2164 - mse: 3.0330 - val_loss: 2.7403 - val_mse: 2.5098\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "{'k': 15, 'lambda_': 5e-05} Test RMSE : 3.4888160133317028 \n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 13.0647 - mse: 13.0630 - val_loss: 12.1600 - val_mse: 12.1585\n",
      "Epoch 2/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 11.8514 - mse: 11.8488 - val_loss: 9.9924 - val_mse: 9.9826\n",
      "Epoch 3/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.0450 - mse: 9.0297 - val_loss: 6.1462 - val_mse: 6.1100\n",
      "Epoch 4/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.2665 - mse: 5.2218 - val_loss: 3.5241 - val_mse: 3.4543\n",
      "Epoch 5/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.9976 - mse: 2.9204 - val_loss: 2.5246 - val_mse: 2.4278\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "{'k': 15, 'lambda_': 2e-05} Test RMSE : 3.488369004272177 \n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 13.1131 - mse: 13.0885 - val_loss: 12.1394 - val_mse: 12.1248\n",
      "Epoch 2/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 11.6751 - mse: 11.6433 - val_loss: 8.9602 - val_mse: 8.7958\n",
      "Epoch 3/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.7078 - mse: 7.4500 - val_loss: 4.8198 - val_mse: 4.2549\n",
      "Epoch 4/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.2389 - mse: 3.5844 - val_loss: 3.6206 - val_mse: 2.7490\n",
      "Epoch 5/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.2631 - mse: 2.3417 - val_loss: 3.2723 - val_mse: 2.2283\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "{'k': 30, 'lambda_': 0.0002} Test RMSE : 3.483633594747269 \n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 13.0838 - mse: 13.0764 - val_loss: 12.1291 - val_mse: 12.1233\n",
      "Epoch 2/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 11.6644 - mse: 11.6542 - val_loss: 9.0623 - val_mse: 9.0201\n",
      "Epoch 3/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.7736 - mse: 7.7077 - val_loss: 4.4421 - val_mse: 4.2931\n",
      "Epoch 4/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.6538 - mse: 3.4777 - val_loss: 2.7955 - val_mse: 2.5487\n",
      "Epoch 5/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.3494 - mse: 2.0853 - val_loss: 2.2966 - val_mse: 1.9875\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "{'k': 30, 'lambda_': 5e-05} Test RMSE : 3.483963354057967 \n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 13.0893 - mse: 13.0859 - val_loss: 12.1579 - val_mse: 12.1551\n",
      "Epoch 2/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 11.7298 - mse: 11.7253 - val_loss: 9.1055 - val_mse: 9.0880\n",
      "Epoch 3/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.7272 - mse: 7.6999 - val_loss: 4.3176 - val_mse: 4.2557\n",
      "Epoch 4/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.5266 - mse: 3.4533 - val_loss: 2.5936 - val_mse: 2.4909\n",
      "Epoch 5/500\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.1404 - mse: 2.0301 - val_loss: 2.0570 - val_mse: 1.9272\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "{'k': 30, 'lambda_': 2e-05} Test RMSE : 3.487266287410911 \n"
     ]
    }
   ],
   "source": [
    "lambdas_ = [0.0002, 0.00005, 0.00002]\n",
    "ks = [15,30]\n",
    "\n",
    "param_grid = { 'k' : ks, 'lambda_' : lambdas_ }\n",
    "best_params, best_score, best_model = grid_search(train, param_grid, get_mf_bias_l2_reg_model,\n",
    "                                      nb_users, nb_movies, validation_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(model_path + \"best_model.keras\")\n",
    "#best_model=keras.models.load_model(model_path + \"best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters : {'k': 30, 'lambda_': 0.0002}\n",
      "Best validation RMSE : 3.483633594747269\n"
     ]
    }
   ],
   "source": [
    "print('Best hyper-parameters : ' + str(best_params))\n",
    "print('Best validation RMSE : ' + str(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Best model test RMSE : 3.4889667328000677 \n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "test_rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Best model test RMSE : %s \" % test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain on all the dataset with the best hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually other hyper-parameters such as the ones of SGD should also be grid-searched, like the number of epochs or the batch size. But that would be a bit long for this course. \n",
    "\n",
    "Now we want to do the best prediction possible, so retrain below your model on the whole dataset, including the test set, with the best values obtained from your grid search to make new predictions with our optimal parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\ML4\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['u__user_id', 'i__movie_id']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 13.0154 - mse: 13.0121 - val_loss: 11.7875 - val_mse: 11.7836\n",
      "Epoch 2/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 10.8418 - mse: 10.8336 - val_loss: 6.7931 - val_mse: 6.7584\n",
      "Epoch 3/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.2986 - mse: 5.2496 - val_loss: 2.9932 - val_mse: 2.9027\n",
      "Epoch 4/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 2.4139 - mse: 2.3132 - val_loss: 2.1199 - val_mse: 1.9933\n",
      "Epoch 5/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 1.7138 - mse: 1.5804 - val_loss: 1.7706 - val_mse: 1.6190\n",
      "Epoch 6/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 1.3804 - mse: 1.2237 - val_loss: 1.5902 - val_mse: 1.4193\n",
      "Epoch 7/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2053 - mse: 1.0303 - val_loss: 1.4877 - val_mse: 1.3015\n",
      "Epoch 8/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0931 - mse: 0.9035 - val_loss: 1.4231 - val_mse: 1.2240\n",
      "Epoch 9/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0335 - mse: 0.8317 - val_loss: 1.3814 - val_mse: 1.1719\n",
      "Epoch 10/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.9667 - mse: 0.7550 - val_loss: 1.3533 - val_mse: 1.1352\n",
      "Epoch 11/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.9326 - mse: 0.7127 - val_loss: 1.3359 - val_mse: 1.1107\n",
      "Epoch 12/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.9025 - mse: 0.6758 - val_loss: 1.3236 - val_mse: 1.0926\n",
      "Epoch 13/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8772 - mse: 0.6449 - val_loss: 1.3154 - val_mse: 1.0796\n",
      "Epoch 14/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.8656 - mse: 0.6287 - val_loss: 1.3089 - val_mse: 1.0692\n",
      "Epoch 15/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.8380 - mse: 0.5974 - val_loss: 1.3049 - val_mse: 1.0620\n",
      "Epoch 16/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.8254 - mse: 0.5818 - val_loss: 1.3027 - val_mse: 1.0573\n",
      "Epoch 17/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.8132 - mse: 0.5673 - val_loss: 1.2993 - val_mse: 1.0521\n",
      "Epoch 18/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.8047 - mse: 0.5571 - val_loss: 1.2993 - val_mse: 1.0504\n",
      "Epoch 19/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7927 - mse: 0.5433 - val_loss: 1.2981 - val_mse: 1.0478\n",
      "Epoch 20/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7799 - mse: 0.5295 - val_loss: 1.2983 - val_mse: 1.0470\n",
      "Epoch 21/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7737 - mse: 0.5222 - val_loss: 1.2979 - val_mse: 1.0460\n",
      "Epoch 22/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7599 - mse: 0.5080 - val_loss: 1.2976 - val_mse: 1.0451\n",
      "Epoch 23/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7599 - mse: 0.5073 - val_loss: 1.2958 - val_mse: 1.0428\n",
      "Epoch 24/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7436 - mse: 0.4906 - val_loss: 1.2971 - val_mse: 1.0438\n",
      "Epoch 25/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.7372 - mse: 0.4839 - val_loss: 1.2971 - val_mse: 1.0436\n",
      "Epoch 26/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7226 - mse: 0.4690 - val_loss: 1.2973 - val_mse: 1.0435\n",
      "Epoch 27/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.7156 - mse: 0.4620 - val_loss: 1.2957 - val_mse: 1.0416\n",
      "Epoch 28/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.7011 - mse: 0.4471 - val_loss: 1.2964 - val_mse: 1.0422\n",
      "Epoch 29/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6941 - mse: 0.4401 - val_loss: 1.2958 - val_mse: 1.0413\n",
      "Epoch 30/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6902 - mse: 0.4360 - val_loss: 1.2969 - val_mse: 1.0423\n",
      "Epoch 31/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6771 - mse: 0.4226 - val_loss: 1.2983 - val_mse: 1.0437\n",
      "Epoch 32/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6744 - mse: 0.4199 - val_loss: 1.2992 - val_mse: 1.0442\n",
      "Epoch 33/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6629 - mse: 0.4080 - val_loss: 1.2987 - val_mse: 1.0435\n",
      "Epoch 34/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6504 - mse: 0.3953 - val_loss: 1.2994 - val_mse: 1.0438\n",
      "Epoch 35/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.6431 - mse: 0.3876 - val_loss: 1.2992 - val_mse: 1.0433\n",
      "Epoch 36/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6341 - mse: 0.3784 - val_loss: 1.3005 - val_mse: 1.0443\n",
      "Epoch 37/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.6248 - mse: 0.3687 - val_loss: 1.3017 - val_mse: 1.0451\n",
      "Epoch 38/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6125 - mse: 0.3560 - val_loss: 1.3032 - val_mse: 1.0461\n",
      "Epoch 39/500\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.6031 - mse: 0.3461 - val_loss: 1.3052 - val_mse: 1.0477\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "X = [dataset[\"userId\"].to_numpy(), dataset[\"movieId\"].to_numpy()]\n",
    "y = dataset[\"rating\"].to_numpy()\n",
    "\n",
    "best_params={'k': 30, 'lambda_': 2e-05}#{'k': 30, 'lambda_': 5e-05}\n",
    "\n",
    "#TOFILL\n",
    "best_model2=get_mf_bias_l2_reg_model(nb_users, nb_movies, **best_params)# k =, lambda_ =)\n",
    "early_stopping = EarlyStopping(monitor='val_mse', patience=10, verbose=1, restore_best_weights=True)\n",
    "history=best_model2.fit(X, y, epochs=500, batch_size=512, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model2.save(model_path + \"best_model2.keras\")\n",
    "#best_model2=keras.models.load_model(model_path + \"best_model2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Best model2 test RMSE : 1.020462960998638 \n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model2.predict(X_test)\n",
    "test_rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Best model2 test RMSE : %s \" % test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend the top-5 movies for the 10 first users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your retrained best model with optimal hyper parameters, compute the predictions for all the ratings that are not in the `dataset` for the 10 first users (indexes from 0 to 9). That means all the movies $i$ that these users $u \\in 0,\\ldots,9$ haven't rated, thus all the $u,i$ combinations that are not in the `dataset` dataframe rows.\n",
    "\n",
    "Order these predicted ratings for these users by decreasing order, and print out the 5 first ones, i.e. the ones that have the highest predicted ratings. Use the *movies.csv* file to print the real titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trick and Test place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "user_id=0\n",
    "X_gen=[np.full(len(movie_ids_map.values()),user_id),\n",
    "        np.array(list(movie_ids_map.values()))]\n",
    "\n",
    "y_gen =best_model2.predict(X_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>5.673655</td>\n",
       "      <td>Great Escape, The (1963)</td>\n",
       "      <td>Action|Adventure|Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0</td>\n",
       "      <td>867</td>\n",
       "      <td>5.664803</td>\n",
       "      <td>Wallace &amp; Gromit: The Wrong Trousers (1993)</td>\n",
       "      <td>Animation|Children|Comedy|Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>0</td>\n",
       "      <td>725</td>\n",
       "      <td>5.624494</td>\n",
       "      <td>Top Hat (1935)</td>\n",
       "      <td>Comedy|Musical|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0</td>\n",
       "      <td>923</td>\n",
       "      <td>5.519928</td>\n",
       "      <td>Grand Day Out with Wallace and Gromit, A (1989)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "      <td>5.495526</td>\n",
       "      <td>Wallace &amp; Gromit: A Close Shave (1995)</td>\n",
       "      <td>Animation|Children|Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId    rating  \\\n",
       "876       0      960  5.673655   \n",
       "799       0      867  5.664803   \n",
       "677       0      725  5.624494   \n",
       "844       0      923  5.519928   \n",
       "557       0      599  5.495526   \n",
       "\n",
       "                                               title  \\\n",
       "876                         Great Escape, The (1963)   \n",
       "799      Wallace & Gromit: The Wrong Trousers (1993)   \n",
       "677                                   Top Hat (1935)   \n",
       "844  Grand Day Out with Wallace and Gromit, A (1989)   \n",
       "557           Wallace & Gromit: A Close Shave (1995)   \n",
       "\n",
       "                                         genres  \n",
       "876                  Action|Adventure|Drama|War  \n",
       "799             Animation|Children|Comedy|Crime  \n",
       "677                      Comedy|Musical|Romance  \n",
       "844  Adventure|Animation|Children|Comedy|Sci-Fi  \n",
       "557                   Animation|Children|Comedy  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build result Data frame\n",
    "df=pd.DataFrame()\n",
    "df['userId']=np.full(len(movie_ids_map.values()),user_id)\n",
    "df['movieId']= movie_ids_map.values()\n",
    "df['rating']= y_gen.T[0]\n",
    "#df['movieId']= np.array(list(movie_ids_map.values()))\n",
    "\n",
    "(df[-df.movieId.isin(dataset[dataset.userId.eq(user_id)].movieId)]\n",
    " .merge(right=movies, left_on='movieId', right_on='movieId').sort_values(axis=0, by='rating', ascending=False)\n",
    " .head(5))#.iloc[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.644897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.383640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.284814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.059553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.698364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1\n",
       "0  0.0  4.644897\n",
       "1  1.0  4.383640\n",
       "2  2.0  4.284814\n",
       "3  3.0  3.059553\n",
       "4  4.0  3.698364"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame([np.array(list(movie_ids_map.values())), y_gen.T[0]]).T\n",
    "df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1525</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982400</td>\n",
       "      <td>Negotiator, The (1998)</td>\n",
       "      <td>Action|Crime|Drama|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>783</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982791</td>\n",
       "      <td>Sword in the Stone, The (1963)</td>\n",
       "      <td>Animation|Children|Fantasy|Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2216</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982176</td>\n",
       "      <td>Goldfinger (1964)</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>830</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983484</td>\n",
       "      <td>Basic Instinct (1992)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1223</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983504</td>\n",
       "      <td>Game, The (1997)</td>\n",
       "      <td>Drama|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1742</td>\n",
       "      <td>2.0</td>\n",
       "      <td>964983546</td>\n",
       "      <td>I Still Know What You Did Last Summer (1998)</td>\n",
       "      <td>Horror|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>919</td>\n",
       "      <td>2.0</td>\n",
       "      <td>964983393</td>\n",
       "      <td>Psycho (1960)</td>\n",
       "      <td>Crime|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1971</td>\n",
       "      <td>2.0</td>\n",
       "      <td>964982588</td>\n",
       "      <td>Mummy, The (1999)</td>\n",
       "      <td>Action|Adventure|Comedy|Fantasy|Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>1673</td>\n",
       "      <td>2.0</td>\n",
       "      <td>964981775</td>\n",
       "      <td>Toys (1992)</td>\n",
       "      <td>Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>2392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>964983504</td>\n",
       "      <td>Talented Mr. Ripley, The (1999)</td>\n",
       "      <td>Drama|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating  timestamp  \\\n",
       "0         0     1525     5.0  964982400   \n",
       "2         0      783     5.0  964982791   \n",
       "3         0     2216     5.0  964982176   \n",
       "20        0      830     5.0  964983484   \n",
       "22        0     1223     5.0  964983504   \n",
       "..      ...      ...     ...        ...   \n",
       "26        0     1742     2.0  964983546   \n",
       "48        0      919     2.0  964983393   \n",
       "6         0     1971     2.0  964982588   \n",
       "152       0     1673     2.0  964981775   \n",
       "165       0     2392     1.0  964983504   \n",
       "\n",
       "                                            title  \\\n",
       "0                          Negotiator, The (1998)   \n",
       "2                  Sword in the Stone, The (1963)   \n",
       "3                               Goldfinger (1964)   \n",
       "20                          Basic Instinct (1992)   \n",
       "22                               Game, The (1997)   \n",
       "..                                            ...   \n",
       "26   I Still Know What You Did Last Summer (1998)   \n",
       "48                                  Psycho (1960)   \n",
       "6                               Mummy, The (1999)   \n",
       "152                                   Toys (1992)   \n",
       "165               Talented Mr. Ripley, The (1999)   \n",
       "\n",
       "                                              genres  \n",
       "0                Action|Crime|Drama|Mystery|Thriller  \n",
       "2                 Animation|Children|Fantasy|Musical  \n",
       "3                          Action|Adventure|Thriller  \n",
       "20                            Crime|Mystery|Thriller  \n",
       "22                            Drama|Mystery|Thriller  \n",
       "..                                               ...  \n",
       "26                           Horror|Mystery|Thriller  \n",
       "48                                      Crime|Horror  \n",
       "6    Action|Adventure|Comedy|Fantasy|Horror|Thriller  \n",
       "152                                   Comedy|Fantasy  \n",
       "165                           Drama|Mystery|Thriller  \n",
       "\n",
       "[232 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## using dataset \n",
    "display(dataset[dataset.userId.eq(user_id)]\n",
    ".merge(right=movies, left_on='movieId', right_on='movieId')\n",
    ".sort_values(axis=0, by='rating', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.644897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.383640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.284814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.059553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.698364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>0</td>\n",
       "      <td>9719</td>\n",
       "      <td>2.594527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>0</td>\n",
       "      <td>9720</td>\n",
       "      <td>2.252120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9721</th>\n",
       "      <td>0</td>\n",
       "      <td>9721</td>\n",
       "      <td>2.294488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9722</th>\n",
       "      <td>0</td>\n",
       "      <td>9722</td>\n",
       "      <td>2.240641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9723</th>\n",
       "      <td>0</td>\n",
       "      <td>9723</td>\n",
       "      <td>3.582020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9724 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId    rating\n",
       "0          0        0  4.644897\n",
       "1          0        1  4.383640\n",
       "2          0        2  4.284814\n",
       "3          0        3  3.059553\n",
       "4          0        4  3.698364\n",
       "...      ...      ...       ...\n",
       "9719       0     9719  2.594527\n",
       "9720       0     9720  2.252120\n",
       "9721       0     9721  2.294488\n",
       "9722       0     9722  2.240641\n",
       "9723       0     9723  3.582020\n",
       "\n",
       "[9724 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "df['userId']=np.full(len(movie_ids_map.values()),user_id)\n",
    "df['movieId']= movie_ids_map.values()\n",
    "df['rating']= y_gen.T[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.DataFrame()\n",
    "# df['userId']=np.full(len(movie_ids_map.values()),user_id)\n",
    "# df['movieId']= movie_ids_map.values()\n",
    "# df['rating']= y_gen.T[0]\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 5 bests for one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top5_for_user(model, user_id, dataset):\n",
    "    \"\"\"\n",
    "    Returns a list of the 5 movies that have the highest ratings among the unrated movies\n",
    "    of user `user_id`, along with a list of their predicted ratings.\n",
    "    \n",
    "    Input :\n",
    "        model : keras.models.Model : A trained matrix factorization model\n",
    "        user_id : int : The user id to use\n",
    "        dataset : DataFrame : The whole dataset, useful to find the movies \n",
    "            the user `user_id` has already rated\n",
    "    \n",
    "    Output :\n",
    "        five_best_movie_ids : list : The five movie ids among unrated movies by user `user_id` \n",
    "            that have the highest predicted ratings, in order\n",
    "        five_best_ratings : list : The corresponding five ratings\n",
    "    \"\"\"\n",
    "    \n",
    "    #TOFILL\n",
    "    # X_gen is build with:\n",
    "    # 1- nb_movies line field with userID\n",
    "    # 2- all the movie ID in the ranking DB\n",
    "    X_gen=[np.full(len(movie_ids_map.values()), user_id),\n",
    "            np.array(list(movie_ids_map.values()))]\n",
    "    \n",
    "    # predict ranking for the user\n",
    "    y_gen =model.predict(X_gen)\n",
    "\n",
    "    # build the data frame of the predict result\n",
    "    df=pd.DataFrame()\n",
    "    df['userId']=np.full(len(movie_ids_map.values()),user_id)\n",
    "    df['movieId']= movie_ids_map.values()\n",
    "    df['rating']= y_gen.T[0]\n",
    "    \n",
    "    #df['movieId']= np.array(list(movie_ids_map.values()))\n",
    "\n",
    "    # only keep (not rated movies) & sort by rating\n",
    "    bestMovies=(df[-df.movieId.isin(dataset[dataset.userId.eq(user_id)].movieId)]\n",
    "     .merge(right=movies, left_on='movieId', right_on='movieId')\n",
    "     .sort_values(axis=0, by='rating', ascending=False))\n",
    "     #.head(5))\n",
    "     #.iloc[:5])\n",
    "    # display (bestMovies.head(5))\n",
    "    five_best_movie_ids = bestMovies['movieId'].head(5).reset_index(drop=True)\n",
    "    five_best_ratings = bestMovies['rating'].head(5).reset_index(drop=True)\n",
    "    \n",
    "    return five_best_movie_ids, five_best_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    960\n",
       "1    867\n",
       "2    725\n",
       "3    923\n",
       "4    599\n",
       "Name: movieId, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    5.673655\n",
       "1    5.664803\n",
       "2    5.624494\n",
       "3    5.519928\n",
       "4    5.495526\n",
       "Name: rating, dtype: float32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TOFILL\n",
    "\n",
    "five_best_movie_ids, five_best_ratings=get_top5_for_user(model=best_model2, user_id=0, dataset=dataset)\n",
    "display(five_best_movie_ids, five_best_ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 5 bests for 10 first users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look for user 0\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "look for user 1\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "look for user 2\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "look for user 3\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "look for user 4\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "look for user 5\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "look for user 6\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "look for user 7\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "look for user 8\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "look for user 9\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_movie0</th>\n",
       "      <th>bestrating0</th>\n",
       "      <th>best_movie1</th>\n",
       "      <th>bestrating1</th>\n",
       "      <th>best_movie2</th>\n",
       "      <th>bestrating2</th>\n",
       "      <th>best_movie3</th>\n",
       "      <th>bestrating3</th>\n",
       "      <th>best_movie4</th>\n",
       "      <th>bestrating4</th>\n",
       "      <th>best_movie5</th>\n",
       "      <th>bestrating5</th>\n",
       "      <th>best_movie6</th>\n",
       "      <th>bestrating6</th>\n",
       "      <th>best_movie7</th>\n",
       "      <th>bestrating7</th>\n",
       "      <th>best_movie8</th>\n",
       "      <th>bestrating8</th>\n",
       "      <th>best_movie9</th>\n",
       "      <th>bestrating9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>960</td>\n",
       "      <td>5.673655</td>\n",
       "      <td>9600</td>\n",
       "      <td>4.330051</td>\n",
       "      <td>224</td>\n",
       "      <td>3.339565</td>\n",
       "      <td>27</td>\n",
       "      <td>4.554001</td>\n",
       "      <td>2416</td>\n",
       "      <td>4.202021</td>\n",
       "      <td>960</td>\n",
       "      <td>4.835576</td>\n",
       "      <td>1938</td>\n",
       "      <td>4.494321</td>\n",
       "      <td>1938</td>\n",
       "      <td>4.044657</td>\n",
       "      <td>277</td>\n",
       "      <td>4.802560</td>\n",
       "      <td>8283</td>\n",
       "      <td>4.287548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>867</td>\n",
       "      <td>5.664803</td>\n",
       "      <td>877</td>\n",
       "      <td>4.326466</td>\n",
       "      <td>910</td>\n",
       "      <td>3.290612</td>\n",
       "      <td>2416</td>\n",
       "      <td>4.469143</td>\n",
       "      <td>27</td>\n",
       "      <td>4.177824</td>\n",
       "      <td>867</td>\n",
       "      <td>4.692817</td>\n",
       "      <td>277</td>\n",
       "      <td>4.493594</td>\n",
       "      <td>2416</td>\n",
       "      <td>4.018974</td>\n",
       "      <td>224</td>\n",
       "      <td>4.662162</td>\n",
       "      <td>8256</td>\n",
       "      <td>4.284374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>725</td>\n",
       "      <td>5.624494</td>\n",
       "      <td>3083</td>\n",
       "      <td>4.230799</td>\n",
       "      <td>1938</td>\n",
       "      <td>3.260505</td>\n",
       "      <td>960</td>\n",
       "      <td>4.469007</td>\n",
       "      <td>510</td>\n",
       "      <td>4.169026</td>\n",
       "      <td>877</td>\n",
       "      <td>4.671494</td>\n",
       "      <td>461</td>\n",
       "      <td>4.381538</td>\n",
       "      <td>224</td>\n",
       "      <td>4.016566</td>\n",
       "      <td>659</td>\n",
       "      <td>4.614788</td>\n",
       "      <td>5938</td>\n",
       "      <td>4.252643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>923</td>\n",
       "      <td>5.519928</td>\n",
       "      <td>1733</td>\n",
       "      <td>4.208825</td>\n",
       "      <td>4421</td>\n",
       "      <td>3.240775</td>\n",
       "      <td>867</td>\n",
       "      <td>4.382720</td>\n",
       "      <td>974</td>\n",
       "      <td>4.149079</td>\n",
       "      <td>74</td>\n",
       "      <td>4.634676</td>\n",
       "      <td>257</td>\n",
       "      <td>4.372938</td>\n",
       "      <td>2370</td>\n",
       "      <td>4.004272</td>\n",
       "      <td>897</td>\n",
       "      <td>4.603109</td>\n",
       "      <td>7181</td>\n",
       "      <td>4.206700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>599</td>\n",
       "      <td>5.495526</td>\n",
       "      <td>314</td>\n",
       "      <td>4.158925</td>\n",
       "      <td>897</td>\n",
       "      <td>3.234787</td>\n",
       "      <td>1887</td>\n",
       "      <td>4.367750</td>\n",
       "      <td>3617</td>\n",
       "      <td>4.148549</td>\n",
       "      <td>599</td>\n",
       "      <td>4.632092</td>\n",
       "      <td>1502</td>\n",
       "      <td>4.336908</td>\n",
       "      <td>1733</td>\n",
       "      <td>4.000002</td>\n",
       "      <td>257</td>\n",
       "      <td>4.560923</td>\n",
       "      <td>7603</td>\n",
       "      <td>4.170399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_movie0  bestrating0  best_movie1  bestrating1  best_movie2  \\\n",
       "0          960     5.673655         9600     4.330051          224   \n",
       "1          867     5.664803          877     4.326466          910   \n",
       "2          725     5.624494         3083     4.230799         1938   \n",
       "3          923     5.519928         1733     4.208825         4421   \n",
       "4          599     5.495526          314     4.158925          897   \n",
       "\n",
       "   bestrating2  best_movie3  bestrating3  best_movie4  bestrating4  \\\n",
       "0     3.339565           27     4.554001         2416     4.202021   \n",
       "1     3.290612         2416     4.469143           27     4.177824   \n",
       "2     3.260505          960     4.469007          510     4.169026   \n",
       "3     3.240775          867     4.382720          974     4.149079   \n",
       "4     3.234787         1887     4.367750         3617     4.148549   \n",
       "\n",
       "   best_movie5  bestrating5  best_movie6  bestrating6  best_movie7  \\\n",
       "0          960     4.835576         1938     4.494321         1938   \n",
       "1          867     4.692817          277     4.493594         2416   \n",
       "2          877     4.671494          461     4.381538          224   \n",
       "3           74     4.634676          257     4.372938         2370   \n",
       "4          599     4.632092         1502     4.336908         1733   \n",
       "\n",
       "   bestrating7  best_movie8  bestrating8  best_movie9  bestrating9  \n",
       "0     4.044657          277     4.802560         8283     4.287548  \n",
       "1     4.018974          224     4.662162         8256     4.284374  \n",
       "2     4.016566          659     4.614788         5938     4.252643  \n",
       "3     4.004272          897     4.603109         7181     4.206700  \n",
       "4     4.000002          257     4.560923         7603     4.170399  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look for the 5 best movies recomendation for the fist 10 \n",
    "df5best=pd.DataFrame()\n",
    "for user in list(user_ids_map.values())[0:10]:\n",
    "    print (f\"look for user {user}\")\n",
    "    five_best_movie_ids, five_best_ratings=get_top5_for_user(model=best_model2, user_id=user, dataset=dataset)\n",
    "    df5best[f\"best_movie{user}\"]=five_best_movie_ids\n",
    "    df5best[f\"bestrating{user}\"]=five_best_ratings\n",
    "\n",
    "display (df5best)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_movie0</th>\n",
       "      <th>best_movie1</th>\n",
       "      <th>best_movie2</th>\n",
       "      <th>best_movie3</th>\n",
       "      <th>best_movie4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>5.673655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>5.664803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>5.624494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>5.519928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>5.495526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     best_movie0  best_movie1  best_movie2  best_movie3  best_movie4\n",
       "876     5.673655          NaN          NaN          NaN          NaN\n",
       "799     5.664803          NaN          NaN          NaN          NaN\n",
       "677     5.624494          NaN          NaN          NaN          NaN\n",
       "844     5.519928          NaN          NaN          NaN          NaN\n",
       "557     5.495526          NaN          NaN          NaN          NaN"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now have a look at what is going on in the embedding space of the movies that we learnt. Our brain cannot picture anything beyond 3 dimensions, and we learnt high dimensional embeddings (k=15 or 30), so we are going to project the movies embeddings on a 2D plane, first with PCA, and then with another algorithm made for visualizing high dimensional spaces called t-sne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already studied PCA, it is a useful technique for dimensionality reduction, but also simply for visualization. Don't forget to scale your embeddings first. To access the embeddings values of your keras model, have a look at the *get_weights()* function.\n",
    "\n",
    "Compute a PCA on all your movies embeddings, get the 2 first principal components, and do a scatter plot of all the movies on a 2D plane, where each movie is a point defined by the two values of the two first principal components of the PCA from its embedding. Add the titles of the movies to each point of the plot (use plotly to do so it will be clearer), and try to see if you can interpret the axes of the PCA through to different movie genres, like in Figure 3 from the article *Matrix Factorization Techniques for Recommender Systems*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "data_2D = pca.fit_transform(X)\n",
    "\n",
    "#TOFILL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-sne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with t-sne, an algorithm specialized for visualizing high dimensional spaces, you can read more about it there : https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#TOFILL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-sne in general tends to preserve local similarities better than PCA. In any case, it's always interesting to try both for visualizing high dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, you can export your embedding and upload them on https://projector.tensorflow.org/ to visualize the embeddings in 3D. You can also use the movies genres from the *movies.csv* file to make one plot for each movie genre and try to see if some parts of the embedding space are representative of a movie genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOING FURTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend movies to yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function that ask you to rate 20 movies, then add your own ratings to the dataset, retrain the model, and compute your own top-5 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def rate_my_movies(my_user_id, dataset, nb_movies, nb_to_rate, movie_ids_map):\n",
    "    \"\"\"\n",
    "    Returns a dataframe in the same format as the dataset dataframe, with\n",
    "    ratings entered by the user for `nb_to_rate` random movies\n",
    "    \n",
    "    Input :\n",
    "        my_user_id : int : The user_id of the new ratings\n",
    "        dataset : DataFrame : The whole dataset \n",
    "        nb_movies : int : Number of unique movie ids\n",
    "        nb_to_rate : int : Number of movies to rate\n",
    "        movie_ids_map : dict : The mapping of original file userId to a new index starting at 0.\n",
    "    \n",
    "    Output : \n",
    "        my_ratings : DataFrame : A dataframe with the same column as `dataset` containing\n",
    "            the new ratings entered by the user\n",
    "    \"\"\"\n",
    "    #TOFILL\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    return my_ratings\n",
    "\n",
    "\n",
    "my_user_id = len(user_ids_map)\n",
    "\n",
    "my_ratings = rate_my_movies(my_user_id, dataset, nb_movies, 20, movie_ids_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_with_me = pd.concat([dataset, my_ratings], axis = 0).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_with_me = [dataset_with_me[\"userId\"].to_numpy(), dataset_with_me[\"movieId\"].to_numpy()]\n",
    "y_with_me = dataset_with_me[\"rating\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model=get_mf_bias_l2_reg_model(nb_users + 1, nb_movies, k = best_params['k'], lambda_ = best_params['lambda_'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_mse', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "best_model.fit(X_with_me, y_with_me, epochs=500, batch_size=512, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_best_movie_ids, five_best_ratings =  get_top5_for_user(best_model, my_user_id, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse the movie embeddings to predict the movies genre with multi-label classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond the goal of predicting missing rating, the matrix factorization techniques also produces vectorial representation of movies and users: their embeddings, what we just visualized for the movies. With a big enough dataset, these embeddings actually are good abstract representations of the movies and of the users, and can be reused as features for other tasks, such as classification.\n",
    "\n",
    "In the *movies.csv*, there is a column that gives the genres of each movie. Let's try to predict the genres of the movies from the embeddings we learnt. As you can see, each movie can have more than one genre, so in classification terms, more than one class. We can achieve that with *multilabel classification*. You can read more about it there: https://scikit-learn.org/stable/modules/multiclass.html\n",
    "\n",
    "Load the movies genre, encode them as binary classes and use the classes imported below to train a multilabel classifier that uses the movie embeddings as features, and the movie genres as classes. Use the *OneVsRestClassifier* with a simple *LinearSVC* without any hyper-parameter tuning. Finally print the test accuracy, F1, precision and recall for each class, as well as the number of time each class appears in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "#TOFILL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rare classes, you should get a very high accuracy, with a very low F1. Indeed these classes are really imbalanced : there are a few positives, hence the classifier is largely biased toward the negatives, and rarely predict a positive for these classes. This is why accuracy is generally a bad measure with imbalanced dataset : the high number of true negatives makes the accuracy number high, while our model is actually barely capable of predicting true positives.\n",
    "\n",
    "Let's compare our classifier performance with a *DummyClassifier*, the dummy classifier takes the ratio $r = \\frac{nb\\_positives}{nb\\_positives + nb\\_negatives}$ as the probability to predict a positive, and then do it randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#TOFILL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, simply respecting the class balance, even at random, produces better F1 on most classes. One way to compensate for class imbalance is to tell the classifier to weight more the true samples at training time, accordingly with the ratio $r$ between true and false samples. With scikit-learn SVM implementation, you can use the argument *class_weight* for setting the weight of the positive and negative samples at training time. See : https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html\n",
    "\n",
    "But if you just want to set the class weights accordingly with the ratio between positives and negatives, you can just set *class_weight = ‘balanced’*. Test it with the LinearSVC classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TOFILL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 is now much better than with the dummy classifier, however is is still not very convincing. This is quite normal given the size of the dataset we are using, which is pretty small to get really meaningful embeddings. But with bigger datasets, reusing embeddings as features for auxiliary tasks such as classification is actually a very effective way of doing so when there is no other informations about the items we try to classify. Here the items are the movies, the dataset doesn't provide more information about them, but one could imagine fetching from internet textual descriptions of the movies and use them as features alongside the embeddings to improve the classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out the different SGD algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the notebook we used the 'adam' `optimizer` to train our model, which is a variation of SGD. Keras proposes different variations of SGD: https://keras.io/optimizers/ . This article gif images gives an intuitive view of their different behavior : https://medium.com/@ramrajchandradevan/the-evolution-of-gradient-descend-optimization-algorithm-4106a6702d39\n",
    "\n",
    "Try a few ones with our model and see how the training and testing loss evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOFILL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the global bias $\\mu$  parameter to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we didn't added the global bias $\\mu$ to our model yet (Equations (4-5) from Koren's paper). Use your best google skills to find a way to add an embedding layer that does that.\n",
    "\n",
    "Hint : Use a constant `Input` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "#TOFILL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement your own Stochastic Gradient Descent for Matrix Factorization with numpy instead of Keras (very optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know everything to implement your own matrix factorization SGD model, all with numpy arrays. Start without the biases again, and without mini-batches. The gradient update equations are described in page 4 of Koren's paper. Let's initialize your $p$ and $q$ embeddings with a gaussian sampling. Print the RMSE at the beginning of each epoch, and finally compute the RMSE of your model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import normal\n",
    "\n",
    "P = normal(size = (nb_users,k))\n",
    "Q = normal(size = (nb_movies,k))\n",
    "\n",
    "gamma = 0.1\n",
    "lambda_ = 0.00001\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    for j in range(train.shape[0]):\n",
    "        u = train['userId'].iloc[j]\n",
    "        i = train['movieId'].iloc[j]\n",
    "        r_ui = train['rating'].iloc[j]\n",
    "        \n",
    "        #TOFILL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
